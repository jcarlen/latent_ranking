\documentclass{article}
\setlength{\oddsidemargin}{0in} 
\setlength{\textwidth}{6.5in} 
\setlength{\evensidemargin}{0in}
\setlength\parindent{24pt}

\usepackage[natbibapa]{apacite}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{array}
\usepackage{fancyvrb}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage{float}
\usepackage{bbm}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{booktabs}
\usepackage{colortbl, xcolor}

%from jss.cls
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\let\proglang=\textsf
\let\code=\texttt

\title{A Latent Space Network Modelling Approach to Ratings with  \\
Applications to Journal and Film Rating}

\author{Jane Carlen \\ \emph{University of California, Los Angeles}}

%\blind{\date{DRAFT COPY\\DO NOT CIRCULATE\\\today}{}}
%\date{}

\begin{document}
\maketitle
\thispagestyle{empty}
%\pagestyle{empty}
\setcounter{page}{0}

\abstract{We introduce a method for rating items based on network data or incomplete pairwise comparison data, employing the latent space network models developed by \citet{hoff02}, \citet{hoff03} and \citet{krivitskyetal09}. Our model estimates positions of items in latent space, along with individualized sender and receiver coefficients that capture powers of transmission for each item. Ratings are derived from the difference in sender and receiver coefficients. The method is ideal for items with nebulous similarities which can exert a range of influences on the strength of ties. Unlike existing rating methods, the latent space network model provides both a measure of uncertainty in estimates and meaningful visualization.

Further, we show that non MCMC-based estimation methods can produce results on par with commonly used MCMC methods in a fraction of the time. In particlar, we develop a quasi-Newton algorithm  for this problem which performs well in applications. This extends the practical use of the latent space ranking method and of certain classes of latent space network models more generally. We present two applications. First, we use the method to rank statistics journals and address the weaknesses of existing ranking methods. Second, we formulate movie ratings for films of several genres and demonstrate the use of latent space positions for genre detection. Our method is implemented in \proglang{R}, using the packages \pkg{latentnet} \citep{latentnet} and \pkg{visNetwork} \citep{visNetwork}}, and supplementary code which is provided. 

\newpage

\section{Introduction} \label{Introduction}

\subsection{Rating Methods for Network Data}\label{Rating Methods}
    
The task of rating items from network or incomplete pairwise comparison data is well studied in some settings, such as ranking web pages. Perhaps the best-known ranking algorithm for network data is Google's PageRank algorithm \citep{pagerank99}. Because it is generalizable, fast, and has a guaranteed solution, it has been applied in many settings, including biology, chemistry, ecology, neuroscience, physics, sports and computer systems \citep{gleich14}. In brief, it ranks pages by the eigenvector of the dominant eigenvalue of a Markov transition matrix which describes traffic flow among web pages. The rating corresponds roughly to the equilibrium amount of time an internet user would spend on a specific web page. It is worth noting that the development of PageRank was influenced by earlier work in citation analysis. \citet{pinski76} proposed a similar eigenvalue-based method for scoring journals, with an application to ranking physics journals. 
% wiki: "The eigenvalue problem was suggested in 1976 by Gabriel Pinski and Francis Narin, who worked on scientometrics ranking scientific journals [7] and in 1977 by Thomas Saaty in his concept of Analytic Hierarchy Process which weighted alternative choices.[8]"

The main advantage of a method like PageRank over raw count-based metrics (including Impact Factor, described below) is that references from highly rated pages (or journals) are more highly valued. As \citet{pagerank99} put it in an early paper, ``we give the following intuitive description of PageRank: a page has high rank if the sum of the ranks of its backlinks is high.'' This is crucial in ranking web pages where most linking pages are not of any interest to a user. However, it is not as important when ranking fairly homogeneous catalogs of items, and in that context can lead to overemphasizing popularity, as we will illustrate in Section \ref{Example1}. 
%Also the web is HUGE but the kinds of things I consider below are smaller enough to navigate, so while losing scalability isn't great, it's not the main focus. Also, new methods being developed to make this scalable? (http://papers.nips.cc/paper/4978-a-scalable-approach-to-probabilistic-latent-space-inference-of-large-scale-networks.pdf)

Eigenfactor \citep{eigenfactor07} is a method similar to PageRank, but tailored specifically to rank journals. The main differences are 1) the data is normalized, i.e., we model the percentage of citations journals send to each other instead of raw counts, and 2) rather than affording every journal a uniform minimum weight
%which ensures a solution and makes it so that if something is pointed to by a lot of sites it will come out decently important, even if those sites aren't important
this amount is scaled to the number of articles published by each journal. (For details of the calculation see \citeauthor{eigenfactor08}.) These changes reflect the greater uniformity and much smaller scale of the journal ranking problem as compared to web-site ranking. The Eigenfactor score can be viewed as the total influence of a journal. In tandem, the Article Influence score also proposed by \citet{eigenfactor07} is a measure of the ``average influence'' of an article in a given journal. It is proportional to the Eigenfactor score divided by the number of articles published by the journal. In Section \ref{Example1} we compare our journal ranking results to rankings by these methods. 
%Eigenfactor may be more appropriate for 'subscription decisions' than rank decisions, where Article Influence may be more appropriate to "measure the average influcence of articles appearing in the same journal" ... "proportional to the Eigenfactor divided by the number of articles." i.e. now penalizing for out citations

%Also:
% HITS uses hub and authority scores. I tried running hits against latent space and page rank results(?)
% not really appropriate for the journal ranking problem

Another area where ratings on incomplete comparison networks have been thoroughly studied is in ranking sport and gaming competitors. A full discussion of available methods is beyond the scope of this paper and we refer the reader to, for example, \citet{barrow} and \citet{stefani}. An example of a network-based ranking system developed for US college football is that of \citet{parknewman05}. %The network density in that application is about 10 percent \citep{parkyook14}, and about 75 percent of matchups are between teams in the same regional conference.
Their method calculates a \textit{win} score for each team as the exponentially decreasing sum of its wins, opponents wins, opponents' opponents wins, etc. A \textit{loss} score is analogously calculated and the final rank of the team is its win score minus its loss score. Their measure can be viewed as an extension of Katz centrality %the authors say it, and see 7.14 of newman. this looks the possible extension of katz centrality given there.

%Further:
%2014 paper by park and Yook? (also sports)
%ecological network?
%elections?

There is a close relationship between rating objects in networks and measuring network centrality. All of the ratings methods we reference are closely connected to an established centrality measure. In particular, the Impact Factor (described in Section \ref{Example1}) is related to degree centrality, PageRank and Eigenfactor are related to eigenvector and Katz centrality, and the Park and Newman method is also related to Katz centrality. 
%ImpactFactor - degree centrality
%PageRank - eigenvector centrality/katz centrality (vs katz: http://www.sci.unich.it/~francesc/teaching/network/pagerank)
%Park and Newman - Katz centrality
%HITS - Authority and hub centrality]
In contrast, the latent space method introduced below makes allowance for the fact that influence and centrality are not synonymous. An item may not be central, but may nonetheless have the ability to influence disparate items, and this is reflected in its rating.

\subsection{Applications of Latent Space Network Models}\label{Applications}

Latent space network models have been used for various applications, but not specifically for rating, as far as we know. For example, \citet{hoffward04} use a latent space model to visualize the structure of relationships between political actors in Central Asia. %it's bilinear though
\citet{gormley07} develop a latent space model for rank data and use it to co-locate voters and candidates in an Irish parliamentary election. \citet{sewellchen15} employ such a model to dynamic network data to study network stability and the relationship between popularity and stability. They subsequently extend their model to fit dynamic clusters \citep{sewellchen16}. 

Although latent space network models have not been used to rank authors or journals, as we do in Section \ref{Example1}, they have been applied previously to analyze citation networks. For example, \citet{sarkarmoore} develop a dynamic latent space model that can track the relationships between authors and their level of influence over time, which they illustrate on NIPS coauthorship data. Latent class network models have also been used to discover communities in citation networks, for example in \citet{leichtetal}, but the addition of latent positions  adds capability to identify externally mislabeled nodes, as we demonstrate in Section \ref{Example2}.

\subsection{Overview}\label{Overview}

The latent space network rating method we introduce uniquely incorporates the following features: 1) accounting for similarity between nodes, whether implicit or through covariates; 2) providing measures of uncertainty in estimates; 3) meaningfully and easily visualizing results; 4) distinction between influence and centrality; and 5) simple implementation in \proglang{R} \citep{r}. The method is applicable to directed networks, including those derived from pairwise comparison data. We focus on the case where the edges are valued and can be reasonably modeled as Poisson-distributed.

Section \ref{Model} of the paper details the latent space network model we employ and its estimation methods. Sections \ref{Example1} and \ref{Example2} describe two applications of the model, first to ranking statistics journals using citation data and second to rating films from several genres. In both applications we discuss the value added through network visualization. Section \ref{Discussion} concludes the paper with a discussion of benefits, limitations, and possible future improvements to the model.

\section{Latent Space Network Model for Rating} \label{Model}

We denote a network of $n$ nodes by its adjacency matrix $Y = \{y_{ij}\}, 1 \leq i,j \leq n$. A dyad in the network consists of two directed edges, $Y_{ij}$ and $Y_{ji}$. The latent space models introduced by \citet{hoff02} assume that nodes in a network have implicit positions in ``social space''. Given these $d$-dimensional positions, $Z$, as well as possible covariates, $X$, and corresponding parameters $\beta$, the probability of an edge is independent of all other edges. Thus, the probability of a graph $Y$ is the product over its edges

$$P(Y|X, \beta, Z) = \prod_{i\neq j} P(y_{ij}|x_{ij}, \beta, z_i, z_j).$$

\citet{hoff03} recasts the parameters with unobserved random effects,

\begin{equation}\label{eq1}
P(Y|X, \beta, \gamma) = \prod_{i\neq j} P(y_{ij}| x_{ij}, \beta, \gamma_{ij}),
\end{equation}


where here we model $\gamma$ as in the ``distance model'' of \citet{hoff03}:

$$\gamma_{ij} = a_i + b_j + \epsilon_{ij},$$

\begin{equation}\label{eq2}
\epsilon_{ij} = f(z_i,z_j) = - \lVert z_i - z_j \rVert.
\end{equation}

We consider $a_i$ and $b_j$ to be node-specific sender and receiver effects. $\lVert z_i - z_j \rVert$ is the Euclidean distance between nodal positions $z_i$ and $z_j$. (\citet{hoff02} also consider an asymmetric projection model which we do not employ.) Although the positions can be in high-dimensional space, we usually consider one to three dimensions for reasons of interpretability, visualization, or parsimony. %Didn't see max on dimension in the package. other distances are theoretically possible but the ergmm package uses Euclidean distance, see "fitting position" article, or projection distance.


Adapting machinery of the generalized linear model (GLM), let

\begin{equation}\label{eq3}
E(y_{ij}) = g^{-1}(\eta_{ij} = \beta' x_{ij} - \lVert z_i - z_j \rVert + a_i + b_j),
\end{equation}

\noindent where $g$ is the GLM link function. In the context of our applications, we assume $y_{ij}$ is Poisson distributed and let $g$ be the standard log link function. In some cases other distributions may be more appropriate, but here we use the Poisson because we are dealing with count data. (A binomial model with constant trials and a Bernoulli model for binary networks can also be implemented in \pkg{latentnet}.) This is in contrast to the binomial distributions of edge weights in the quasi-Stigler model described in Section~\ref{QS}. Unlike the quasi-Stigler model the estimates are not conditioned on the total weight of each dyad ($y_{ij} + y_{ji}$). 

% latentnet doesn't allow for a unique number of trials in a binomial distribution on each node, but I may code that and use it in an example. Pavel said he would add it in the package if I do.
% Can also use optim to get a quick estimate with binomial likelihood.

We note some features of the model:

\begin{itemize}

\item Increasing distance between $z_i$ and $z_j$ implies decreasing expectation of $y_{ij}$. One way to view this is as controlling for similarity between nodes. Nodes with salient similarites are likely to have fitted positions relatively close together. Some of the magnitude of their connection is attributable to their similarly, and the rest to their individual sender ("push") and receiver ("pull") effects.

\item The effect of positions on expected edge weights is symmetric, affecting both edges in a dyad equally. Positions influence the model via the total dyad weight. To condition on the total weight, as in the quasi-Stigler model, eliminates the value of estimated positions.

\item The \textit{rating} or \textit{score} of node $i$ is its receiver minus sender coefficient, $a_i - b_i$. Its \textit{rank} is derived from its order among the ratings.

\end{itemize}

\subsection{Parameter Estimation}\label{Parameter Estimation}

In this section we discuss two methods of parameter estimation for the latent space model. The first is a Markov chain Monte Carlo method of the type employed previously (see \citet{hoff02}, \citet{hoff03} and \citet{krivitskyetal09}, for example). The second is a quasi-Newton algorithm we have developed for this model. Both methods embed the model in a Bayesian framework and may use the same parameter initialization, but the update methods differ. We discuss first the overlapping aspects of the two methods, and then the particular aspects of each method in subsections \ref{MCMC} and \ref{QN}. 

Both estimation methods embed the model in the same Bayesian framework with corresponding dependence structure. The aim is to maximize the posterior distribution of the parameters, $P(\theta|Y) \propto P(Y|\theta)P(\theta)$. We adapt Equation \ref{eq1} for the case when the random effects are as described in (\ref{eq2}), and our only nodal covariate is the intercept term, $B_0$.

\begin{equation}\label{eq4}
P(\theta|Y) \propto P(Y|\theta)P(\theta) = \prod_{i\neq j} P(y_{ij}|\beta_0, z_i, z_j, a_i, b_j)P(\theta).
\end{equation}

%"A closed form expression for the desired conditional distribution is generally unavailable" \citep{hoff03} (When? Here it is available)

We posit independent normal distributions for the components of $\gamma_i$, $i = 1,....,n$ \citep{hoff03}.

$$a_i \sim N(0, \sigma_a^2))$$
$$b_i \sim N(0, \sigma_b^2))$$
$$z_i \sim MVN_d(0, I_d*\sigma_z^2))$$ %I switched mean from \mu to 0

We expand Equation \ref{eq4}:

\begin{equation}\label{eq5}
P(Y|\theta)P(\theta) = \prod_{i\neq j} P(y_{ij}|\beta_0, z_i, z_j, a_i, b_j)P(a|\sigma_a^2)P(b|\sigma_b^2)P(z|\sigma_z^2)P(\beta_0)P(\sigma_a^2)P(\sigma_b^2)P(\sigma_z^2)
\end{equation}

Equation \ref{eq5} reflects the dependence structure of the parameters as displayed in Figure \ref{fig:dep}. As stated above we assume $y_{ij}|\beta_0, z, a, b$ is Poisson distributed with mean parameter given by Equation \ref{eq3}, where $B = B_0$ and $g^{-1} = exp$.

\begin{figure}
  \centering
    \includegraphics[width=0.3\textwidth]{dependency_struct.pdf}
    \caption{Dependence structure of the latent space sender-receiver model.}
  \label{fig:dep}  
\end{figure}

We place priors on the elements of $\beta$, $\sigma_z^2$, $\sigma_a^2$ and $\sigma_b^2$.

$$\beta \sim N(\textbf{0}, I\sigma_\beta^2)$$ %ergmm default 0,9
$$\sigma_a^2 \sim \text{Scale-inv-}\chi^2 (v_a, s^2_a))$$ %ergmm default 3,1
$$\sigma_b^2 \sim \text{Scale-inv-}\chi^2 (v_b, s^2_b))$$ %ergmm default 3,1
%documentation for rsender/rreceiver says prior for variance of those effects has scale-inverse-chi-squared distribution which is equivalent to the inverse gamma described in the papers, just reparameterized.-->
$$\sigma_z^2 \sim \text{Scale-inv-}\chi^2 (v_z, s^2_z))$$ %ergmm determined by default function below -  


The estimation algorithm of \pkg{latentnet} sets default values for the hyperparameters to generate diffuse ditributions on the prior parameters. The default value for $\sigma_\beta^2$ is $9$ to allow a wide range of $\beta$ values.   %hoff03 uses 100. Is wider better? 
Low degrees of freedom ($v_a$ = $v_b$ = $3$) reflect uncertainty in the values of $\sigma_a^2$ and $\sigma_b^2$, while the default scale parameters ($s^2_a$ = $s^2_b$ = $1$) curtail them to a wide but reasonable range. The default values for $v_z$ and $s^2_z$ are $\sqrt{n}$ and $\frac{1}{8}\sqrt[\leftroot{-3}\uproot{3}d/2]{n}$. These values reflect that larger networks tend to take up more space, but as observed network size increases the influence of prior variance should decline. For discussion of the choice of hyperparameters see \citet{krivitskyetal09} and \citet{latentnet_jss}. We employ the same default values for our quasi-Newton algorithm. These values are fixed throughout the estimation process. %these defaults assume no clusters in the model

<<r more_prior_notes, eval = F, echo = F, warning = F, message= F>>=
#InitErgmm.euclidean<-function(model, d, G=0, var.mul=1/8, var=NULL, var.df.mul=1, var.df=NULL, mean.var.mul=2, mean.var=NULL, pK.mul=1, pK=NULL)

# What is the motivation for these functions? Documented somewhere?

#1. Z.var - scale parameter of the inverse chi square prior on var of z's
#  if(!("Z.var" %in% names(model[["prior"]]))) model[["prior"]][["Z.var"]]<-model[["prior"]][["Z.var.mul"]]*(network.size(model[["Yg"]])/max(1,model[["G"]]))^(2/model[["d"]])
#DEFAULT: 1/8 * #vertices / max(1, #clusters)^(2/dimension)

#2. Z.var.df - dof parameter of the inverse chi square prior on var of z's
#  if(!("Z.var.df" %in% names(model[["prior"]]))) model[["prior"]][["Z.var.df"]]<-model[["prior"]][["Z.var.df.mul"]]*sqrt(network.size(model[["Yg"]])/max(1,model[["G"]]))
#DEFAULT: 1 * sqrt(#vertices) / max(1, #clusters)
# why sqrt? based on presumed density/dependence?

#3. Z.mean.var - variance of the gaussian prior on cluster means, if necessary
# if(!("Z.mean.var" %in% names(model[["prior"]]))) model[["prior"]][["Z.mean.var"]]<-model[["prior"]][["Z.mean.var.mul"]]*model[["prior"]][["Z.var"]]*max(1,model[["G"]])^(2/model[["d"]])
#DEFAULT:  2 * Z.var * max(1, #clusters)^(2/dimension)

#4. Z.pK - parameter (#clusters) of the dirichlet prior on cluster assignment, if nec.
#if(!("Z.pK" %in% names(model[["prior"]]))) model[["prior"]][["Z.pK"]]<-model[["prior"]][["Z.pK.mul"]]*sqrt(network.size(model[["Yg"]])/max(1,model[["G"]]))
#DEFAULT:  1 * sqrt(#vertices)/max(1,#clusters)
@

Both estimation methods described below require us to supply or generate initial parameter values. The default initializations for MCMC estimation, as implemented in \pkg{latentnet}, are functions of the observed network. This may speed convergence in some cases, but in our applications in low dimension we find that random initialization can perform as well or better. Our quasi-Newton method employs random initialization on a reasonable scale, without loss of speed or performance. \newline

\emph{MCMC Initialization}:

\begin{itemize}
\item $z^{(0)}$: The positions are initialized through either multidimensional scaling or normal draws. In the former, the geodesic distances for all dyads are computed from the binary adjacency matrix $Y_b$. Disconnected pairs are given distances of $n$. The initial value $z^{(0)}$ is then computed by multidimensional scaling, returning optimal $d$-dimensional coordinates whose Euclidean distances best approximate the geodesic distances between nodes. In the latter, $z^{(0)}$ is generated via independent draws from a normal distribution. \citet{hoff02} note that the choice of initialization does not impact their results. 

\item $\displaystyle \sigma_z^{2(0)} = var(z^{(0)})$

\item $\displaystyle a_i^{(0)} =  logit \left( \frac{Y_{b_{i \cdot}}  + 1}{n - 1 + 2} \right) - \frac{1}{n}\sum_{j=1}^{n} logit \left( \frac{Y_{b_{i \cdot}} + 1}{n - 1 + 2} \right)$

The initialization of sender parameters shown above is derived by considering initial nodal degrees as binomially distributed with $n-1$ trials, observed success probability $\frac{Y_{b_{i \cdot}}}{n-1}$, and a uniform prior on success probability. As a reminder, $Y_b$ denotes the binary adjacency matrix and $Y_{b_{i \cdot}}$ denotes the $ith$ row sum of $Y_b$. The initialization of receiver coefficients is analagous. %n-1 is the number of possible edges on each node. the +1(num), +2(denom) is as though a^(0) is a prediction/new draw of the number of edges when edges ~ binomially with total trials n-1, observed success prob rowsums/(n-1), and with a uniform prior on the success prob (see gelman p. 36)
% See ergmm.initvals, bayes.prop

\item $\displaystyle \sigma_a^{2(0)} = var(a^{(0)})$

\item $\displaystyle b_i^{(0)} = logit \left( \frac{Y_{b_{\cdot i}}  + 1}{n - 1 + 2} \right) - \frac{1}{n}\sum_{i=1}^{n} logit \left( \frac{Y_{b_{\cdot i}} + 1}{n - 1 + 2} \right)$

\item $\displaystyle \sigma_b^{2(0)} = var(b^{(0)})$

\item $\displaystyle \beta_0^{(0)} = logit\left( \frac{1}{n(n-1)}\sum_{i,i\neq j}\mathbbm{1}(y_{ij} > \overline{y_{ij}})\right) + \frac{1}{{n \choose 2}}\sum_{i,i<j}{\lVert z^{(0)}_i - z^{(0)}_j \rVert}$ 

The initial intercept is composed of an ``edge intercept,'' a valued-network analog of graph density, plus a ``distance intercept,'' the average initial pairwise distance.

% edge intercept + distance intercept
% logit(mean(indicator(Y_ij > mean(Y_ij))))
% See ergmm.initvals 
% Yg<- model[["Yg"]]
% Ym<-getYm(Yg,model[["response"]]) #getYm returns as.matrix.network(Yg, "citations", matrix.type="adjacency") with NA's on diag.
% Ym01<-Ym>mean(Ym,na.rm=TRUE)

% pm[["beta"]]<-logit(mean(Ym01,na.rm=TRUE))+if(!is.null(pm[["Z"]]))mean(dist2(pm[["Z"]])) else 0 #edge intercept + distance intercept

\end{itemize}

\emph{Quasi-Netwon Initialization}:

\begin{itemize}
\item $z^{(0)}$: Standard normal draws by default, or multidimensional scaling as for MCMC estimation.

\item $\displaystyle a^{(0)}, b^{(0)}$: Standard normal draws.

\item $\displaystyle \sigma_a^{2(0)}, \sigma_b^{2(0)}, \sigma_z^{2(0)}$: User-supplied value, defaults to 10.

\item $\displaystyle \beta_0^{(0)} = 0$.

\end{itemize}

\subsubsection{MCMC Estimation}\label{MCMC}

With the introduction of latent space network models, \citet{hoff02} developed an MCMC estimation algorithm to fit a model without random sender and receiver effects. \citet{hoff03} added the capacity to fit random effects, and \citet{krivitskyetal09} extended the model further by allowing clustering terms. In this section we present an overview of the MCMC estimation described by those authors, and embellish it with details from the \pkg{latentnet} implementation (\cite{latentnet_jss}, \cite{latentnet}). The process returns a sample from the posterior parameter distribution and desired point estimates, such as a maximum likelihood estimate, posterior mean and mode. 
\newline



\emph{MCMC Parameter Updates}:  \newline

Before starting an MCMC chain, \pkg{latentnet} employs an intermediate non-convex optimization step. It uses the bounded quasi-Newton optimization routine of \citet{lbfgsb}, as implemented in the \code{optim} function of \proglang{R}. This returns starting values for MCMC with higher posterior likelihood than the initial values. In Section \ref{??} we compare the gain in posterior likelihood from this optimization routine to the value added from the MCMC chain and to the results of our quasi-Newton algorithm. 

After intermediate optimization, the MCMC chain runs through a suitably long burn-in period. If the automated burn-in length is insufficient, proper length can be determined by carrying out MCMC diagnostics on the results, such as those in the \code{mcmc.diagnostics} method of \pkg{latentnet}. Once starting values for the MCMC sampling are determined, parameters are updated as follows:  

%what is the ordering/grouping of parameter updates? latentnet allows for group.deltas for proposing changes to multiple parameters simultaneously. When are they updated singly vs as a group?

%how does latentnet's adaptive sampling work, e.g. how are proposal dist. parameters updated?

\begin{itemize}

\item $\sigma^2_a, \sigma^2_b, \sigma^2_z$: 

The variances of the sender, receiver, and position parameters may be sampled directly from their posterior distributions because they were assigned conjugate priors. 

$$\displaystyle \sigma^2_a|a \sim \text{Scale-inv-}\chi^2 (v_a + n, \frac{v_a s^2_a + \sum_{i=1}^n{a^2_i}}{v_a + n}))$$

$$\displaystyle \sigma^2_b|b \sim \text{Scale-inv-}\chi^2 (v_b + n, \frac{v_b s^2_b + \sum_{i=1}^n{b^2_i}}{v_b + n}))$$

$$\displaystyle \sigma^2_z|z \sim \text{Scale-inv-}\chi^2 (v_z + n*d, \frac{v_z s^2_z + \sum_{i=1}^{n*d}{z_{i,d}^2}}{v_z + n*d}))$$

\item Actor-specific parameters, $a, b, z$:

The sender, receiver and position parameters cannot be sampled directly and may be strongly correlated. They are updated for each actor in random order by Metropolis-Hastings block updates.

  \begin{enumerate}
  %could be metrpolis since symmetric proposal distribution
  
  \item Propose $z_i^*, a_i^*, b_i^*$ from symmetric proposal distributions. %s, $J(z|z^{(t)})$.
  $$z_i^* \sim MVN_d(z_i, \tau_z^2I_d)$$
  $$a_i^* \sim N(a_i, \tau_a^2)$$
  $$b_i^* \sim N(b_i, \tau_b^2)$$

  \item Accept as a block with probability $min(1, \frac {P(Y|z^*, a^*, b^*, \beta) P(z^*)P(a^*)P(b^*)} {P(Y|z, a, b, \beta) P(z)P(a)P(b)}$).

  %\item $\theta\setminus z$: Metropolis-Hastings \citep{hoff03}.

  \end{enumerate}
  
\item $\beta$, shift of random effects, position scale:

  To speed convergence, a simultaneous shift in $\beta$ and the random effects and a rescaling of the positions is proposed. The magnitude of the shifts and multiplier is proposed by: 
  $$(h_\beta, h_a, h_b, h_z) \sim MVN_4(0, \tau_{\beta,a,b,z})$$
  $$ \beta^* = \beta +h_\beta $$
  $$ a^* = a +h_a $$
  $$ b^* = b + h_b $$
  $$ z^* = exp(h_z)z $$
  $$ \sigma_z^{2*} = exp(2h_z)\sigma_z^2 $$
  
  The move is block-accepted or rejected. For discussion of the acceptance probability see Section 3.2 of \citet{krivitskyetal09}.

  \item \textit{Proposal Variances} $\tau_z^2, \tau_a^2, \tau_b^2, \tau_{\beta,a,b,z}$:
  
  The variances of the proposal distributions are set adaptively during the burn-in period to stay near a fixed acceptance rate, with a default target rate of 0.234 (\cite{latentnet_jss} following \cite{nealandroberts}).
  
\end{itemize}


%This is just basic MH so I don't need to describe until I get more detail on the prosal distribution. [In \citep{shortreed06} proposal distributions are Gaussian centered at current values, $\theta^{(t)}$ with some standard deviation, $\delta_{\beta}$ or $\delta_z$. Is this still true in latentnet? If so, and since these are symmetric, is all done with Metropolis?]

%1. Propose $\theta^*$ from a proposal distribution, $J(\theta|\theta^{(t)})$ %[individual or group?]

%2. Compute acceptance probability $r = min(1, \frac{P(Y|\theta^{*})P(\theta^{*})J(\theta^{(t)}|\theta^{*})}  {P(Y|\theta^{(t)})P(\theta^{(t)})J(\theta^{*}|\theta^{(t)})})$ %lots of cancellation here if only updating one parameter at a time

%3. Set $\theta^* = \theta^{(t+1)}$ with probability $r$, otherwise $\theta^{(t+1)} = \theta^{(t)}$


\emph{MCMC Post-processing}:  \newline
  
  The likelihood depends on positions only through their pairwise distances, and is invariant to rotations, reflections and translations of the positions. We are interested in the posterior variance in positions that comes from changing distances between points rather than distance-preserving transformations. One way to address this and stabilize our estimates is to store not the sampled positions, but a transformed set that has minimal squared distance to a set of reference positions. This is the Procustean transformation is used by \citet{hoff02}, where $z^*_{store} = argmin_{Tz^*}tr(z_{ref} - Tz^*)^\top(z_{ref} - Tz^*)$, and $T$ is the set of distance-preserving transformations.\\
  
There may also be strong correlation and near unidentifiability between a node's position and other parameters, especially its sender or receiver coefficient if it is poorly connected. To resolve this \citet{shortreed06} consider the configuration of positions that is optimal in the sense of minimizing Bayes risk with a Kullback-Leibler (KL) loss function. Their ``MKL'' parameter estimates minimize the posterior expectation of the KL divergence from their predictive distribution of networks to the posterior predictive distribution of networks: $\displaystyle E_{Z, a, b, \beta|Y_{obs}}\left[\sum_y log(\frac{P(Y|Z, a, b, \beta)}{P(Y|\widetilde{Z} \widetilde{a}, \widetilde{b}, \widetilde{\beta})})P(Y|Z, a, b, \beta)\right]$. These positions are more stable than standard point estimates since they average over all networks and their parent parameters. They require the posterior sample to calcualate, so unlike in \citet{hoff02} the sampled positions are transformed with MKL positions as reference after the chain is complete.

<<r invchisq, eval = T, results = 'hide', echo = F, cache = T, warning = F, message = F>>=
#took these from geoR package which was crashing

rinvchisq <- function (n, df, scale = 1/df) 
{
  if ((length(scale) != 1) & (length(scale) != n)) 
    stop("scale should be a scalar or a vector of the same length as x")
  if (df <= 0) 
    stop("df must be greater than zero")
  if (any(scale <= 0)) 
    stop("scale must be greater than zero")
  return((df * scale)/rchisq(n, df = df))
}

dinvchisq <-function (x, df, scale = 1/df, log = FALSE) 
{
  if (df <= 0) 
    stop("df must be greater than zero")
  if (scale <= 0) 
    stop("scale must be greater than zero")
  nu <- df/2
  if (log) 
    return(ifelse(x > 0, nu * log(nu) - log(gamma(nu)) + 
                    nu * log(scale) - (nu + 1) * log(x) - (nu * scale/x), 
                  NA))
  else return(ifelse(x > 0, (((nu)^(nu))/gamma(nu)) * (scale^nu) * 
                       (x^(-(nu + 1))) * exp(-nu * scale/x), NA))
}
@

%Estimation is implemented in the \code{ergmm} function of \pkg{latentnet} \citep{latentnet_jss}. 

\subsubsection{Quasi-Newton Estimation}\label{QN}

While the MCMC sample is useful for interval calculations, the rankings themselves rely only on a point estimate. A variety of strategies are available for this optimization problem, but here we present a quasi-Newton method that is fast, transparent, and performs well in applications. \newline

  
\emph{Parameter Updates}:  \newline

For each parameter we aim to update it to a local maximum of the posterior parameter distribution conditioned on all others. A Gibbs sampler cycles through parameters updates for $z, \sigma_z^2, \beta, a, \sigma_a^2, b, \sigma_b^2.$ The conditional variance parameters have closed-form updates. For parameters without closed-form updates, we take a step whose size depends on the first-order partial derivative and direction depends on the unmixed second-order partial. Derivative calculations are detailed in Appendix \ref{Appendix2}. If the step crosses a zero we continue to search within smaller and smaller intervals until finding the zero up to a pre-set tolerance, or until the stepsize falls below a user-specified $\epsilon$. Otherwise, we expand the search up to a window of, at most, twice the largest position coordinate. We cycle through parameter updates for a user-supplied number of cycles, and take as our final estimate the one achieved with the highest posterior probability. Our algorithm differs from common quasi-Newton methods primarily in it adjustments to stepsize and use of only unmixed second-order partial derivatives (the diagonal of the Hessian). The steps are detailed in Algorithm \ref{QNalg}. \newline

%Advantage of gradient descent:
%- can pick out nodes causing problems due to lack of connectivity by non-converging derivative
%- know for sure and easily when it's converged to local opt.
%- widely used and accesible to a wide audience

\begin{algorithm}[!]\label{QNalg}
\DontPrintSemicolon
\KwData{$Y, D, runs, \epsilon$}

Set hyperparameters (see Section \ref{Parameter Estimation}) and algorithmic parameters $\bf \Delta$, $\epsilon, tol, j_{max}, runs$.\;
Initialize model parameters $z, a, b, B_0, \sigma_a^{2}, \sigma_b^{2} \sigma_z^{2}$.\;

\While{$r \leq runs$} {
  $Z = z$; $Z$ stored and used for calculations, updated after all $z_{i,d}$ are.\;
  Update $z$:\;
  \For{$i\in permute(1:n)$}{
  
    \For{$d\in permute(1:D)$}{
    
      \While{$|\frac{\partial \mathbbm{llik}}{\partial z_{i,d}}| > tol~ \text{\bf and } j \leq j_{max}$}{
      
        $z^*_{i,d} = z_{i,d} + \Delta_{z_{i,d}}*sgn(\frac{\partial \mathbbm{llik}}{\partial z_{i,d}})*-sgn(\frac{\partial^2 \mathbbm{llik}}{\partial^2 z_{i,d}}$)\;
        
          \If{  $sgn(\frac{\partial \mathbbm{llik}}{\partial z^*_{i,d}}) \neq 
                 sgn(\frac{\partial \mathbbm{llik}}{\partial z_{i,d}})$}   {
                 
              $s = seq(z_{i,d}, ~z^*_{i,d}, ~length = 11)$ \;
              $z_{i,d} = argmin(|s - z_{i,d}| :
                         sgn(\frac{\partial \mathbbm{llik}}{\partial s}) \neq
                         sgn(\frac{\partial \mathbbm{llik}}{\partial z_{i,d}}))$\;
              update $\frac{\partial \mathbbm{llik}}{\partial z_{i,d}}$ and
                     $\frac{\partial^2 \mathbbm{llik}}{\partial^2 z_{i,d}}$ \;          
              $\Delta_{z_{d,i}} = \frac{1}{10}*\Delta_{z_{d,i}}$\;
    
              \If{$\Delta_{z_{d,i}} < \epsilon$}{\bf break}
              
          } \Else{
                  
              \If{$\Delta_{z_{d,i}} \leq max(|z|)$} {$\Delta_{z_{d,i}} = 2*\Delta_{z_{d,i}}$}
              
            } \Else { 
                
                If no local max is forthcoming, look in both directions\;
                $s = seq(z_{i,d} - \Delta_{z_{d,i}},
                         z_{i,d} + \Delta_{z_{d,i}}, ~length = 101) \setminus z_{i,d}$\;
                
                $\Delta_{z_{d,i}} = |argmin(|\frac{\partial \mathbbm{llik}}{\partial s}|) - z_{i,d}|$\;
                $z_{d,i} = |argmin(|\frac{\partial \mathbbm{llik}}{\partial s}|)$\; %update lower case z (not upper case Z yet)
                update $\frac{\partial \mathbbm{llik}}{\partial z_{i,d}}$ and
                       $\frac{\partial^2 \mathbbm{llik}}{\partial^2 z_{i,d}}$ \;  
              }
      j = j+1
      } 
    } 
  }
  $\sigma^2_z = \frac{v_z*s^2_z + \sum z^2}{n*D + 2 + v_z}$\;
  Update $\beta_0$:\;
  \While{$|\frac{\partial \mathbbm{llik}}{\partial \beta_0} > tol|$}{
  
      $B^*_0 = B_0 + \Delta_{B_0}*sgn(\frac{\partial \mathbbm{llik}}{\partial \beta_0})$\;
      \If {$sgn(\frac{\partial \mathbbm{llik}}{\partial \beta_0}  \neq
          sgn(\frac{\partial \mathbbm{llik}}{\partial \beta^*_0}))$} { 
          
          $s = seq(B_0, ~B^*_0, ~length = 11)$\;
          $B_0 = argmin(|s - B_0| :
                         sgn(\frac{\partial \mathbbm{llik}}{\partial s}) \neq
                         sgn(\frac{\partial \mathbbm{llik}}{\partial B_0}))$\;
          $\Delta_{B_0} = \frac{1}{10}\Delta_{B_0}$\;
          update $\frac{\partial \mathbbm{llik}}{\partial B_0}$\;
        
      } \Else {$\Delta_{B_0} = 2 * \Delta_{B_0}$}
    }
  Update $a_i, i \in permute(1:n)$  by same process as $\beta_0$\;
  $\sigma^2_a = \frac{v_a*s^2_a + \sum a^2}{n + 2 + v_a}$\;
  Update $b$ analagous to $a$\;
  \If {$llik(\theta_{current})>$ previous max} 
    {store $\hat{\theta} = \theta$}
}
\caption{Latent Space Network Quasi-Newton Algorithm\label{QNalg}}
\end{algorithm}

\emph{Post-processing}:  \newline

We check that all first derivates at our estimate are within the pre-set tolerance near zero. We also look for any sign that this point is non-optimal by checking that the unmixed second-order partials  for the coordinates are negative. For other parameters they are always negative (see Appendix \ref{Appendix2}). In trials, we have found that the few coordinates with positive second derivates at the estimate also had extremely low degree. We removed these points because they lack the necessary connectivity to accurately determine several correlated parameters, i.e. sender, receiver and coordinates. Thus, the algorithm output provides a test for the necessary connectivity on a case-by-case basis. This has a similar stabilizing effect to the MKL estimates produced from the MCMC output, though with the cost of a small amount of data. \newline

The main argument against using a quasi-Newton estimation method is that it is not guaranteed to converge to a global optimum since the likelihood function is not convex. However, there are several reasons why it is often still successful in practice. First, in applications well suited to latent space network rating the search space for the positions is relatively small. This is especially true when positions are in low dimension, which they are likely to be given the value of network visualization. Second, although MCMC estimation is theoretically guaranteed to converge to the true distribution, if the search space is large and the likelihood function jagged it may face prohibitively slow mixing time and fail to converge to the global optimum. It is easier to diagnose specific points of non-covergence in the quasi-Newton method using the stored derivatives. Third, the speed of the quasi-Newton method means we can consider many initial values to increase our chance of finding the a global optimimum. Lastly, we are still able to use MCMC estimation to provide a check on our fit. Using the quasi-Newton estimate to seed the MCMC chain we can generate a useful sample from the posterior and may be able to improve on our results while still reducing the overall time to fit. In our trials on networks of up to several hundred nodes, results from quasi-Newton closely approximate those from MCMC.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SETUP FOR APPLICATION SECTION %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<r setup, echo = F, include=FALSE, warning = F, message= F, cache = T, results = 'hide'>>=
knitr::opts_chunk$set(echo = FALSE, results = 'hide')
library(ergm)
library(ernm)
@

<<r setup2, cache = T, echo = F, results='hide', warning=F, echo = F, message=F>>=
library(latentnet)
library(ergm.count)
#load matrix

Cmatrix <- as.matrix(read.csv("~/Documents/citation/Citation_supplement/Data/cross-citation-matrix.csv", row.names = 1)) #47 x 47 #

#Self-citations are removed: The highest raw counts are from self-citations of CSDA (486) and StMed (628), which would seem to skew any analysis of importance. The authors exclude self-citations for the Stigler method: "Both the eigenfactor and the article influence score are computed over a 5-year time period, with journal self-citations removed to eliminate possible sources of manipulation."

Cmatrix.diag = Cmatrix #store a copy before removing diag
diag(Cmatrix) = rep(0,47) #shouldn't actually matter, as.network zeros out diag

#Note the use of the tranposed Cmatrix in the next line to correspond to standard i,j entry = citation FROM i to j. Original Cmatrix has i,j indicates citation from j to i.

Cnet = as.network(t(Cmatrix), directed=T, matrix.type="a", ignore.eval=F,  
       names.eval="citations") #as valued net, see \cite{krivitsky2015}

#as a binary network
Cbinet <- as.network(t(Cmatrix))

#cited/citing
cited = rowSums(Cmatrix) #citations in
citing = colSums(Cmatrix) #citations out
cite.ratio = cited/citing

#normalized
Cmatrix.norm = t(Cmatrix)/citing #entries are % of i's citations to j (column)
Cnet.norm = as.network(Cmatrix.norm, directed=T, matrix.type="a", ignore.eval=F,
            names.eval="citations")
@

<<r setup_jrss, cache = T, echo = F, results='hide', warning=F, echo = F, message=F, dependson = "setup">>=
#code from JRSS-PR-SA-Dec-13-0008_supplement.R to the paper
journal.abbr <- rownames(Cmatrix)

Tmatrix <- Cmatrix + t(Cmatrix)
diag(Tmatrix) <- diag(Cmatrix.diag)

journals.cluster <- hclust(d = as.dist(1 - cor(Tmatrix)))
#plot(journals.cluster, sub = "", xlab = "")
#cutree(journals.cluster, h = 0.6)  
library(BradleyTerry2)

Cdata <- countsToBinomial(Cmatrix)
fit <- BTm(outcome = cbind(win1, win2), player1 = player1, player2 = player2, data = Cdata)

npairs <- NROW(Cdata)
njournals <- nlevels(Cdata$player1)
phi <- sum(residuals(fit, "pearson")^2) / (npairs - (njournals - 1))

## 3.1 Journal residuals
journal.res <- rep(NA, njournals)
res <- residuals(fit, type = "pearson")
coefs <- c(0, coef(fit)) # 0 is the coefficient of the first journal
for(i in 1:njournals){
    A <- which(Cdata$player1 == journal.abbr[i])
    B <- which(Cdata$player2 == journal.abbr[i])
    y <- c(res[A], -res[B])
    x <- c(-coefs[Cdata$player2[A]], -coefs[Cdata$player1[B]])
    journal.res[i] <- sum(y * x) / sqrt(phi * sum(x ^ 2))
}
names(journal.res) <- journal.abbr

library(qvcalc)
cov.matrix <- matrix(0, nrow = njournals, ncol = njournals)
cov.matrix[-1, -1] <- vcov(fit)
qse <- qvcalc(phi * cov.matrix, estimates = c(0, coef(fit)),
              labels = journal.abbr)
#qse[["covmat"]] = cov.matrix*phi

export.scores <- qse$qvframe$estimate
export.scores <- export.scores - mean(export.scores)
names(export.scores) <- journal.abbr

sort.id <- sort(export.scores, decreasing = TRUE, index.return = TRUE)$ix
fit.table <- data.frame(quasi = export.scores[sort.id], qse = qse$qvframe$quasiSE[sort.id])
rownames(fit.table)
rownames(fit.table)[c(1,6,20)] = c("JRSS-B", "JRSS-A", "JRSS-C")
match(rownames(fit.table),Cnet%v%"vertex.names")
fit.table2 = fit.table[order(match(rownames(fit.table),Cnet%v%"vertex.names")),]
@

<< llik_and_latent_qn, cache = T, echo = F, results='hide', warning = F, message = F, dependson = c("setup_jrss", "latent_sr2_plot")>>=

#source necessary functions and adding some other helpful things:

source("./latent_ranking_repo/ls_quasi_newton.R")

# helper function
dist2 <- function(Z) {
  as.matrix(dist(Z, upper = T))
}


# contains, llik, log-likelihood function, off by a constant: 
# contains lsqn, the latent space quasi-netwon function
@

In the next section we apply latent space rating to rank a set of statistics journals. We evaluate the output and compare it to existing journal-ranking methods.

%could potentially embed users in the same network...for later

\section{Ranking Statistics Journals Using Citation Data}\label{Example1}

In this section we examine rankings of 47 statistics and probability journals. The data we consider was first gathered and analyzed by \citet{varinetal} from Journal Citation Reports \citep{JCR}. It consists of a $47 \times 47$ matrix of directed citation counts, encompassing within-network citations from 2001 to 2010. \citeauthor{varinetal} selected this $47$-journal subset from the full set of $110$ statistics and probability journals because their quasi-Stigler model, presented below, requires that journals are fairly homogeneous and have a high level of citation exchange. %"A key requirement for the methods that are described here, as well as in our view for any sensible analysis of citation data, is that the journals jointly analysed should be as homogeneous as possible. Accordingly, analyses are conducted on a subset of the journals from the statistics and probability category, among which there is a relatively high level of citation exchange."" [@varinetal]

%The percent of citations to/from other statistics journals considered is roughly 15 to 60 percent. The median fraction of sent citations lost by subsetting from statistics journals is 4%; received is 7%. <!--of the statistics and probability category of JCR-->

There is a well documented need for a journal ranking system better than the `Impact Factor' (IF). IF is the most commonly referenced measure of journal influence and importance. It is the only such measure listed on the sidebar of a journal's Wikipedia page. IF measures how frequently articles from a specific journal are cited: An IF of $1.0$ means that articles published by that journal in the last two years have been cited once on average \citep{JCR}. Journal Citation Reports also publish modified versions of IF that exclude journal self-citations or alter the size of the time window to one or five years.

% The Immediacy Index only averages over citations receved in the last year, while the IF5 expands the window to five years. The IFno excludes journal self-citations \citep{varinetal}. This addresses a major criticism of the impact factor, which is that journals can artificially inflate their score, whether intentionally or not, by encouraging cross-citations in published articles. Changing the size of the window for citations balances the criticism that articles may not achieve peak influence for several or more years, a lag that depends on the publication field, with the desire to include newer journals in the rankings and measure immediate impact.
%A 5-year Impact Factor is also published --  The 5-year journal Impact Factor is the average number of times articles from the journal published in the past five years have been cited in the JCR year. It is caclulated by dividing the number of citations in the JCR year by the total number of articles published in the five previous years.
%JCR Year (Journal Citation Report Year): The year of the JCR edition displayed in the top right-hand corner of the page. Each JCR year contains one year of citation data. You select the JCR year on the Welcome page.-->

<<r cite_cor, echo = F, results = 'hide', eval = T, cache = T, dependson = c("setup", "setup_jrss")>>=
ij = t(Cmatrix)[lower.tri(t(Cmatrix), diag = F)]
ji = Cmatrix[lower.tri(Cmatrix, diag = F)]
cor(ij, ji)
@

Variable time windows and exclusion of self-citations address two problems with the Impact Factor, but there are additional problems. First, there is no normalization for article length or out-citations, which can drive up IF. Whether planned or not, there is documented reciprocity in citations between journals. (For example, in the data described below the correlation in one-way citations, i.e. $i \to j$ and $j \to i$ is $.57$.) Second, the distribution of citations counts by article is very long tailed, with a few articles receiving many citations and most receiving only a few. As David Colquhoun writes in the Discussion on the paper by \citet{varinetal}, ``It has been obvious for a long time that it is statistically illiterate to characterize very skew distributions by their mean. And it is statistically illiterate to present point estimates with no indication of their uncertainty'' (\citeauthor{varincomment}). 
%discuss later how poisson modelling (or binary) is good for this? is it?
John Aston comments further that this is ``inherently dangerous if weight is given to such metrics in crucial decisions such as grant awards or promotion and tenure cases'' \citep{varincomment}. %Additionally, it is fair to argue that authors should not be judged at all on the journal ranking (importance by association) but we're just not addressing that here. that's for another paper. 

\subsection{The Quasi-Stigler Model} \label{QS}
 
\citet{varinetal} introduce the \textit{quasi-Stigler} model to address the criticisms above. The model measures each journal's ```propensity to export intellectual influence''' (\citeauthor{varinetal}, quoting Stephen Stigler). The rank of journal $i$ is determined by its \textit{export score}, $u_i$, under the assumption that citations counts, $C_{ij}$, are quasi-binomially distributed as follows:

\begin{equation}\label{eq4a}
\begin{aligned}
E(C_{ij}) &= t_{ij}\pi_{ij} \\
\pi_{ij} &= logit^{-1}(u_j - u_i) \\
& = \frac{exp(u_j - u_i)}{1 + exp(u_j - u_i)} \\
var(C_{ij}) &= \phi t_{ij} \pi_{ij} (1 - \pi_{ij})
\end{aligned}
\end{equation}

% \mu_i = b_i - a_i, \text{ where } C_{ij} \text{ is quasi-binomially distributed and } E(C_{ij}) = t_{ij}\exp{(a_i+b_j)}. 

\noindent where $t_{ij}$ is the observed total number of citations between journals $i$ and $j$, i.e.~$t_{ij} = c_{ij} + c_{ji}$. The notation here is slighlty different than in \cite{varinetal} due to transposition of the citation matrix $\{c_{ij}\}$. We note as \citeauthor{varinetal} that the export scores could be obtained as estimates from a quasibinomial GLM with logit link.
% see note in code chunk about how response and weights are set in R for glm, 

<<r glm, eval = T, cache = T, echo = F, results = 'hide', dependson= c("setup", "setup_jrss", "latent_sr1"), fig.keep='none', warning=F>>=

library("extraDistr") #for rbern

Tmatrix <- Cmatrix + t(Cmatrix)

# 1. Binomial GLM ####

# build design matrix - adjusted to not repeat observations, since they should be independnet

n = 47
k = 1
x1 = matrix(0, choose(n, 2), n)
for (i in 1:(n-1)) { #sender
  for (j in (i+1):n) { 
    x1[k,i]=1;
    x1[k,j]=-1;
    k = k + 1
    }
}
x1[,1] = 0 #forces first coef to NA, later set -> 0

#response 
y = as.vector(t(Cmatrix))/as.vector(Tmatrix)
y = y[which(lower.tri(Cmatrix))]
y[is.nan(y)]=0

# model
g1 = glm(y~x1-1,family = quasibinomial(link="logit"), weights = Tmatrix[lower.tri(Cmatrix)])
g1$coefficients[1] = 0
# Note that this is one way to set up the quasibinomial glm in R: 
# "As a numerical vector with values between 0 and 1, interpreted as the proportion of successful cases (with the total number of cases given by the weights)."
# AIC NA because fit by quasi-likelihood

# Results Identical to Sigler

cor(fit.table2$quasi, g1$coefficients, use="pairwise.complete.obs")
    
plot(fit.table2$quasi, g1$coefficients, ylab = "glm", xlab = "Stigler") 
    #shifted by -.7 = fit.table2$quasi[47]

summary(y-predict(g1)*as.vector(Tmatrix))

# Overdispersion - no need to estimate seperately - now agres with paper (after removing repeats from design matrix), 1.759
summary(g1)$dispersion

## 1a. Binomial GLM sender + receiver ####

#Setting it up with "sender"" and "receiver" effects in the design matrix gives basically the same results but it's superfluous, as the "sender" and "receiver" coefficents are perfectly negatively correlated (we're really fitting the differences).

#build design matrix:
x1a = matrix(0,n^2,2*n)
for (i in 1:n) { #sender
  for (j in 1:n) { 
    if (i != j) {
      x1a[n*(i-1)+j,i]=1;
      x1a[n*(i-1)+j,j+n]=1;
    }
  }
}

#g1a = glm(y~x1a-1,family = quasibinomial(link="logit"), weights = as.vector(Tmatrix))

#identical to Stigler up to scaling and loss of 1 DOF (last value NA) :
#cor(fit.table2$quasi, g1a$coefficients[1:47]-g1a$coefficients[48:94], use="pairwise.complete.obs") #=1

#"receiver" and "sender" coefficents perfectly negatively correlated.
#cor(g1a$coefficients[1:47], g1a$coefficients[48:94], use = "complete.obs")

# 2. Poisson GLM (compare to latent.srp1) ####

#response
y2 = as.vector(t(Cmatrix))

#model
g2a = glm.fit(x1a-1, y2, family = poisson(link="log"))
# matches latent.srp1. (where no option for weights or quasi)
# latent.srp1 was the sender receiver only model with fixed effects
# what if weighted and quasi? more appropriate? should these be options of ergmm?
# remember with binomial we have the added constraint that y_ij + y_ji = 1

#  g2a
# MKL S-R fit estimates almost match (shifted) latent.srp1 estiamtes
# Are the underlying models the same, just by different fits?
# '"glm.fit" uses iteratively reweighted least squares (IWLS)' (always same output)
# ergmm uses mcmc (output differs slightly each time)

#plot(latent.srp1$mkl$beta[48:94] - latent.srp1$mkl$beta[1:47],
 #    g2a$coefficients[48:94] - g2a$coefficients[1:47])
#cor(latent.srp1$mkl$beta[48:94] - latent.srp1$mkl$beta[1:47],
#    g2a$coefficients[48:94] - g2a$coefficients[1:47], use="complete.obs") #.999

#Poisson S-R GLM also close to Stigler:
cor(fit.table2$quasi, g2a$coefficients[1:47] - g2a$coefficients[48:94], 
    use="complete.obs")
plot(fit.table2$quasi, g2a$coefficients[1:47] - g2a$coefficients[48:94])

# 3. Simulate function for quasibinomial GLM | Quasi-Stigler using beta-binomial (used in later chunks) ####

# based on a quasi-binomial glm, return a list of matrices of predicted
simulate.qs <- function(g1, nsim = 10) {
  
  P = g1$fitted.values #or P = inv.logit(x1 %*% c(0, fit$coefficients)) 
  PW = g1$prior.weights
  phi = summary(g1)$dispersion
  
  # set alpha and beta to agree with above mean and var
  mean1 = PW*P
  var1 = phi*PW*P*(1-P)
  B = (1-P)/P
  D = phi*P*(1-P)
  alpha = (PW*B - D*(1+B)^2)/(D*(1 + B)^3 - (B+B^2))
  beta = alpha*(1-P)/P
  mean2 = PW*alpha/(alpha + beta) 
  net.dyads = length(g1$fitted.values)
  var2 = PW*alpha*beta*(alpha + beta +PW)/((alpha + beta)^2 * (alpha + beta +1))
  n = ncol(g1$model$x1)
  k = 1
  x1 = matrix(0, choose(n, 2), n)
  for (i in 1:(n-1)) { #sender
    for (j in (i+1):n) { 
     x1[k,i]=1;
      x1[k,j]=-1;
     k = k + 1
     }
  }
  x1[,1] = 0 #forces first coef to NA, later set -> 0
  
  # sample
  g = matrix(0, net.dyads, nsim)
  mats = list(nsim)
  for (i in 1:nsim) {
    sample1 = rep(0, net.dyads)
    for (j in 1:net.dyads) {
      #if (PW[i]==0) {return(0)}
      if (PW[j]==1) {sample1[j] = rbern(1, P[j])}
      if (PW[j] > 1) {sample1[j] = rbbinom(1, size = PW[j], 
                                           alpha = alpha[j], beta = beta[j])}
    }
    y1 = sample1/g1$model$`(weights)`
    y1[is.nan(y1)]=0
    g = glm(y1~x1-1, family = quasibinomial(link="logit"),
                weights = g1$model$`(weights)`)$fitted.values
    mat = matrix(0, n, n)
    mat[lower.tri(mat)] = (g1$model$`(weights)`)*g
    mat = t(mat)
    mat[lower.tri(mat)] = (g1$model$`(weights)`)*(1-g)
    mats[[i]] = t(mat)
  }
  return(mats)
  
}

@

Uncertainty in the export scores is conveyed through the \textit{quasi-variance}, $qvar_i$, of each $\mu_i$. The quasi-variances are estimated to minimize the difference between the true pairwise variances, $var(\hat{\mu}_i - \hat{\mu}_j)$, and a quasi-variance approximation, $qvar_i+qvar_j$. Although they could convey exact variances, the authors prefer quasi-variances and quasi-standard errors (QSE) because they can be succinctly displayed alongside export scores.

To connect the Quasi-Stigler model to the latent space model, consider the quasi-symmetry formulation of the model (see \citeauthor{varinetal} (4), with some notation changes), where the export score is expanded $\mu_i = b_i - a_i$. As in the latent space model, $a_i$ and $b_i$ are sender and receiver coefficients, respecitively. If we constrain $E(C_{ij}) + E(C_{ji}) = t_{ij}$, then the expectation term reduces to $ E(C_{ij}) = t_{ij} exp(a_i + b_j).$

% need to check the last statement again?
% Should the quasi-symmetry formulation have the additional constraint explicitly that E(c_ij) + E(c_ji) = T_ij,
% i.e. exp(a_i + b_j) + exp(a_j + b_i) = 1 ?

\subsection{Comparison of Journal Rankings} \label{Comparison}

We compare the output of our latent space model in two dimensions to the quasi-Stigler model and others discussed in Section \ref{Introduction}. The \proglang {R} code used to implement our model is included in the supplementary material. After considering several estimates, we present MKL parameter estimates from MCMC estimation with random initilization. These estimates have the highest posterior probability and produce the same rankings as the best MLE estimate. We compared results with three-dimensional positions but found no significant advantage to the three-dimensional model to justify the additional parameters and more cumbersome visualization.

%%%%%%%%%%%%%%%%%%%
% CITATION MODELS %
%%%%%%%%%%%%%%%%%%%

<<r latent_sr0, eval = T, results = 'hide', echo = F, cache=T, cache.comments = FALSE, warning= FALSE, dependson = c("setup", "setup2"), highlight = FALSE>>=

latent.srp0 = ergmm(Cnet ~ rsender + rreceiver,
                    response = "citations", family = "Poisson.log", seed = 30,
                    tofit = c("mcmc", "mkl", "procrustes", "mle"),
                    control = ergmm.control(burnin = 100000, interval = 500,
                                            sample.size = 5000, mle.maxit = 50))
@

<<r latent_sr2, eval = T, results = 'hide', echo = F, cache=T, cache.comments = FALSE, warning= FALSE, dependson = c("setup", "setup2"), highlight = FALSE>>=

t1.srp2 = Sys.time()
latent.srp2 = ergmm(Cnet ~ euclidean(d = 2) + rsender + rreceiver,
                    response = "citations", family = "Poisson.log", seed = 30,
                    tofit = c("mcmc", "mkl", "procrustes", "mle"),
                    control = ergmm.control(burnin = 3000000, interval = 500,
                                            sample.size = 5000, mle.maxit = 100))
t2.srp2 = Sys.time()
# The \code{euclidean(d=2)} argument indicates that the latent positions are two-dimensional.
# reponse argument conveys a valued network 
# checked mcmc.diagnostics and they look fine
# mcmc.diagnostics(latent.srp2)
# Raftery Lewis diagnsotic suggests 10000 burnin, but I increased it because acceptance was low and there seemed to be a transition after the burnin period
# Far fewer than the default mle.maxit = 100 is needed

@

<< latent_qn, eval = T, echo = F, results = 'hide', cache=T, cache.comments = FALSE, warning= FALSE>>=

#best trial after several initiations
set.seed(3)

t1 = Sys.time()
latent_qn = lsqn(t(Cmatrix), runs = 100, tol = .01)
    #best results with these settings ^
    #better to do more initializations with fewer runs than vice versa
t2 = Sys.time()

@

<< latent_sr2_init_qn, eval = F, results = 'hide', echo = F, cache=T, dependson = "latent_qn", cache.comments = FALSE, warning= FALSE>>=

# No particular gain from using quasi-Newton to initialize beyond gain from the random initialization method of QN
t1.init.qn = Sys.time()
latent.srp2.init.qn = ergmm(Cnet ~ euclidean(d = 2) + rsender + rreceiver,
       response = "citations", family = "Poisson.log", seed = 30,
       tofit = c("mcmc", "mkl", "procrustes", "mle"),
       control = ergmm.control(burnin = 50000, interval = 500,
                               sample.size = 5000, mle.maxit = 100),
       user.start = with(latent_qn$map, list(Z=Z, sender=sender, receiver=receiver,
                         beta = beta, sender.var = sender.var, receiver.var = receiver.var,
                         Z.var = Z.var)))
t2.init.qn = Sys.time()
@

<< latent_sr2_init_r, eval = T, results = 'hide', echo = F, cache = T, cache.comments = FALSE, warning= FALSE, dependson = c("llik_and_latent_qn")>>=

#random initation of sender and receiver, and scaling Z helps the model fit
D = 2; N = nrow(Cmatrix)
Z_dist = dist2(t(Cmatrix))
Z = cmdscale(Z_dist, k = D)
Z = Z/max(abs(Z))
a = rnorm(N) #rep(0, N) # #sender
b = rnorm(N) #rep(0, N) # #receiver

t1.init.r = Sys.time()
latent.srp2.init.r = ergmm(Cnet ~ euclidean(d = 2) + rsender + rreceiver,
                                response = "citations", family = "Poisson.log", seed = 30,
                                tofit = c("mcmc", "mkl", "procrustes", "mle"),
                                control = ergmm.control(burnin = 500000, interval = 500,
                                                        sample.size = 5000, mle.maxit = 100),
                                user.start = list(Z = Z, sender = a, receiver = b, beta = 0,
                                                  sender.var = var(a), receiver.var = var(b),
                                                  Z.var = var(as.vector(Z))))
t2.init.r = Sys.time()
@

<< latent_sr2_init_r.sann, eval = T, results = 'hide', echo = F, cache=T, cache.comments = FALSE, warning= FALSE>>=

latent.srp2.init.r.sann = ergmm(Cnet ~ euclidean(d = 2) + rsender + rreceiver,
                                response = "citations", family = "Poisson.log", seed = 30,
                                tofit = c("mcmc", "mkl", "procrustes", "mle"),
                                control = ergmm.control(burnin = 50000, interval = 500,
                                                        sample.size = 5000, mle.maxit = 100,
                                                        optim.method = "SANN"),
                                user.start = list(Z = Z, sender = a, receiver = b, beta = 0,
                                                  sender.var = var(a), receiver.var = var(b),
                                                  Z.var = var(as.vector(Z))))
@

<< latent_sr2_init_r.bfgs, eval = T, results = 'hide', echo = F, cache=T, cache.comments = FALSE, warning= FALSE>>=
latent.srp2.init.r.bfgs = ergmm(Cnet ~ euclidean(d = 2) + rsender + rreceiver,
                                response = "citations", family = "Poisson.log", seed = 30,
                                tofit = c("mcmc", "mkl", "procrustes", "mle"),
                                control = ergmm.control(burnin = 50000, interval = 500,
                                                        sample.size = 5000, mle.maxit = 100,
                                                        optim.method = "BFGS"),
                                user.start = list(Z = Z, sender = a, receiver = b, beta = 0,
                                                  sender.var = var(a), receiver.var = var(b),
                                                  Z.var = var(as.vector(Z))))

@

% PageRank does do something that other methods i talk about don't, which is weight citations by importance of the citing journal.

<< pagerank, eval = T, cache = T, echo = F, results = 'hide',dependson = c("setup", "setup_jrss", "latent_sr2"), fig.keep = 'none', message = F, warning = F>>=

# "Page rank is the best-known technique for link-based importance ranking"
# https://www.cs.umd.edu/class/spring2008/cmsc828g/Slides/node-ranking.pdf

# PageRank has been applied to citation data:
# http://arxiv.org/pdf/0901.2640.pdf <- prob most useful, good summary
# http://arxiv.org/pdf/1012.4872.pdf (damping factor)
# http://onlinelibrary.wiley.com/doi/10.1002/asi.21452/epdf (weighted page rank)

# apply page rank ####
Cgraph = igraph::graph.adjacency(t(Cmatrix), weighted=T) #transpose so that i,j indicates citation from i to j.
#get.edge.attribute(Cgraph, "weight")
Cgraph.page.rank = igraph::page.rank(Cgraph, damping = .95)$vector #"If weights arg is NULL and the graph has a weight edge attribute then that is used."
# note, EXTREMELY fast
#       page rank normalizes so doing that wouldn't change results

# compare results to other ranks ####

## to cited/citing ratio
plot(Cgraph.page.rank, cite.ratio)
cor(Cgraph.page.rank, cite.ratio) #.68

## to quasi-stigler

### scores
plot(Cgraph.page.rank, fit.table2$quasi, type = "n")
text(labels = names(Cgraph.page.rank), x = Cgraph.page.rank, y = fit.table2$quasi, cex = .5, xlab = "PageRank", ylab = "quasi-Stigler", srt = -45)
cor(Cgraph.page.rank, fit.table2$quasi) #.659 with damping at .95, and .65 with damping at .85

### ranks
temp = data.frame(row.names = names(Cgraph.page.rank))
temp[,1] = rank(Cgraph.page.rank)
temp[,2] = rank(fit.table2$quasi)
plot(temp, type = "n", xlab = "PageRank", ylab = "quasi-Stigler")
text(labels = rownames(temp), x = temp[,1], y = temp[,2], cex = .5)

### raw counts
cor(Cgraph.page.rank, colSums(t(Cmatrix))) #.985 - correlates very highly with number of  citations received
plot(Cgraph.page.rank, colSums(t(Cmatrix)))
#plot(vc2, colSums(t(Cmatrix))) how would latent space compare?
@

<<r Eigenfactor, eval = T, echo = F, cache = T, results = 'hide', fig.keep = 'none', dependson = c("latent_srp2")>>=

# http://www.eigenfactor.org/projects/journalRank/rankings.php?search=XY&year=2010&searchby=isicat&orderby=Eigenfactor
# 2010, going back five years

EF = c(0.004,0.003,0.035,0.002,0.008,0.005,0.02,0.018,0.012,0.004,0.003,0.006,0.002,0.022,0.002,0.003,0.002,0.002,0.04,0.002,0.004,0.007,0.011,0.002,0.007,0.021,0.004,0.003,0.017,0.007,0.004,0.002,0.002,0.006,0.006,0.006,0.002,0.038,0.005,0.001,0.001,0.002,0.011,0.008,0.007,0.006,0.003)

AI = c(.9, .7, 3.3, .6, 1.6, .8, 1.6, 2.4, 2.3, 1.2, .3, .3, .5, .8, .9, .6, .6, .7, 3.3, .3, .6, 1.6, .9, .5, 1.8, 4.8, 1.0, .4, .6, 1.7, .9, .9, .5, 1.4, 2.0, 1.8, .5, 1.3, 1.5, .8, .5, .4, .4, 3.4, 1.0, 1.4, 1.2)

names(EF) =  names(AI) = c('AmS','AISM','AoS','ANZS','Bern','BioJ','Bcs','Bka','Biost','CJS','CSSC','CSTM','CmpSt','CSDA','EES','Envr','ISR','JABES','JASA','JAS','JBS','JCGS','JMA','JNS','JRSS.A','JRSS.B','JRSS.C','JSCS','JSPI','JSS','JTSA','LDA','Mtka','SJS','StataJ','StCmp','Stats','StMed','SMMR','StMod','StNee','StPap','SPL','StSci','StSin','Tech','Test')

par(mfrow = c(2,2))
#vs latent 
plot(fit.table2$quasi, EF, main = as.character(round( cor(fit.table2$quasi, EF), 3)), type ="n")
text(names(EF), x = fit.table2$quasi, y = EF, cex = .6) 
#the fact that StMed scores very highly on eigenfactor is a knock against it. StMed is middle of the road in cited/citing ratio and latent score and pagerank
plot(fit.table2$quasi, AI, main = as.character(round( cor(fit.table2$quasi, AI), 3)), type ="n")
text(names(AI), x = fit.table2$quasi, y = AI, cex = .6) 

#vs page rank
#PageRank does not directly penalize out-links, even though journals which cite much more often than they are cited are less likely to be highly regarded. 

plot(Cgraph.page.rank, EF, main = as.character(round( cor(Cgraph.page.rank, EF), 3)), type ="n")
text(names(EF), x = Cgraph.page.rank, y = EF, cex = .6) 

plot(Cgraph.page.rank, AI, main = as.character(round( cor(Cgraph.page.rank, AI), 3)), type ="n")
text(names(AI), x = Cgraph.page.rank, y = AI, cex = .6) 

# compared to latent and colored by cluster
#par(mfrow = c(1,1))
#plot(vc2, AI, main = as.character(round( cor(vc2, AI), 3)), type ="n")
#text(names(AI), x = vc2, y = AI, cex = .9, col = cutree(journals.cluster, h = 0.6)+3) #shows AI seems to place "general" and "computational" publications lower as opposed to latent method (because light blue color at the bottom)

# Eigenfactor correlattion to ratio of in to out citations
cor(EF, colSums(t(Cmatrix))/rowSums(t(Cmatrix)))
@

<<r IF, eval = T, echo = F, cache = T, results = 'hide', fig.keep = 'none', warning = F, message = F >>=

#This is taken from Table 4 of varinetal, via their journal-scores.csv file in their supplement folder. BUT not all the names match up so I made the journal-scores_edited file. 

IF1 = c(0.981,
0.966,
2.94,
0.618,
1,
1.438,
1.764,
1.833,
2.769,
0.689,
NA,
0.351,
0.5,
1.089,
NA,
0.75,
0.86,
0.722,
2.063,
0.306,
1.073,
1.206,
1.01,
NA,
2.57,
3.5,
0.645,
0.469,
0.691,
NA,
0.678,
0.873,
0.584,
0.835,
NA,
1.851,
0.519,
2.328,
1.768,
0.714,
0.322,
NA,
0.443,
2.48,
0.956,
1.56,
NA)

#Same as above, but with 2010 missing values supplied from https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
IF2 = c(0.981,
0.966,
2.94,
0.618,
1,
1.438,
1.764,
1.833,
2.769,
0.689,
0.343, #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
0.351,
0.5,
1.089,
1.645, #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
0.75,
0.86,
0.722,
2.063,
0.306,
1.073,
1.206,
1.01,
0.455, #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
2.57,
3.5,
0.645,
0.469,
0.691,
2.647, #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
0.678,
0.873,
0.584,
0.835,
2.0, #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
1.851,
0.519,
2.328,
1.768,
0.714,
0.322,
0.595, #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?
0.443,
2.48,
0.956,
1.56,
1.036) #https://jcr.incites.thomsonreuters.com/JCRJournalHomeAction.action?

#From varinetal Table4. Filling in missing values would require JCR login
IFno = c(0.752,
0.966,
2.573,
0.582,
0.964,
1.278,
1.601,
1.686,
2.615,
0.676,
NA,
0.311,
0.5,
0.815,
NA,
0.707,
0.8,
0.667,
1.929,
0.281,
0.76,
1.137,
0.816,
NA,
2.354,
3.427,
0.566,
0.429,
0.594,
NA,
0.632,
0.836,
0.573,
0.813,
NA,
1.743,
0.519,
2.072,
1.725,
0.686,
0.305,
NA,
0.356,
2.08,
0.889,
1.387,
NA)

IF2.rank = rank(-IF2, na.last = "keep")
IFno.rank = rank(-IFno, na.last = "keep")
@

<<r HITS, eval = F, echo = F, cache = F>>=
library(igraph)

# http://stackoverflow.com/questions/29911300/how-to-get-the-hits-function-in-r-tool
HITS<-function(g,k)  { 
    adj <- g
    nodes <- dim(adj)[1] 
    auth <- c(rep(1,nodes)) 
    hub <- c(rep(1,nodes)) 
    for(i in 1:k){ 
        t_adj <- t(adj) 
        auth <- t_adj%*%hub 
        hub <- adj%*%auth 
        sum_sq_auth <- sum(auth*auth) 
        sum_sq_hub <- sum(hub*hub) 
        auth <- auth/sqrt(sum_sq_auth) 
        hub <- hub/sqrt(sum_sq_hub) 
    } 
    result <- data.frame(auth = auth,hub = hub)   
    return(result) 
}

hits <- HITS(Cmatrix, 100)
par(mfrow = c(2,2))
cor(vc2, hits$auth) #not similar
cor(vc2, hits$hub) #a bit similar
plot(vc2, hits$hub)
cor(Cgraph.page.rank, hits$auth) #a bit simlar
plot(Cgraph.page.rank, hits$auth) 
cor(Cgraph.page.rank, hits$hub) #very similar
plot(Cgraph.page.rank, hits$hub)
cor(Cgraph.page.rank, hits$auth+hits$hub) 
plot(Cgraph.page.rank, hits$auth+hits$hub) 
@

<<r summarytable, eval = T, cache = T, echo = F, results = 'asis', dependson = c("setup", "setup_jrss", "latent_sr2", "pagerank", "Eigenfactor", "IF"), warning = F, message = F >>=

# varintable <- read.csv("/Users/jac/Documents/citation/Varin_Cattelan_Firth_supplement/Data/journal-scores.csv")
# can't use this table directly it includes too many journals

summarytable_rate = round(data.frame("Latent Space" = latent.srp2$mkl$receiver -
                                       latent.srp2$mkl$sender,
                          "quasi-Stigler"= fit.table2$quasi,
                          "PageRank" = Cgraph.page.rank,
                          "Eigenfactor" = EF,
                          "Article Influence" = AI,
                          "Impact Factor" = IF2),3)

summarytable_rank = data.frame(
                          "Latent Space" = order(order(latent.srp2.init.r$mkl$receiver -
                                        latent.srp2.init.r$mkl$sender, decreasing = T)),
                          "quasi-Stigler"= order(order(fit.table2$quasi, decreasing = T)),
                          "PageRank" = order(order(Cgraph.page.rank, decreasing = T)),
                          "Eigenfactor" = order(order(EF, decreasing = T)),
                          "Article Influence" = order(order(AI, decreasing = T)),
                          "Impact Factor" = IF2.rank)

rownames(summarytable_rank) = rownames(summarytable_rate) 

library(xtable)
summary_xtable_rank <- xtable(summarytable_rank, caption = "Compared Rankings", digits = 0, label = "summarytable_rank")
   
summary_xtable_rate <-xtable(round(cor(summarytable_rate),2), caption = "Correlation Table of Journal Ratings Methods", label = "correlation_table")

col1 <- rep("\\rowcolor[gray]{0.95}", 4)
print.xtable(summary_xtable_rank, booktabs = TRUE,
             table.placement = getOption("xtable.table.placement", "!"),
             add.to.row = list(pos = as.list(c(2, 7, 25, 18)), command = col1))

print.xtable(summary_xtable_rate)   
@

Table \ref{summarytable_rank} compares journal rankings from the latent space model, quasi-Stigler model, PageRank, Eigenfactor, Article Influence, and Impact Factor.
%Explain how I fit all these/whether the data's from. Include code for latent space model?
Comparisons to other versions of the Impact Factor can be found in Table 4 of \citeauthor{varinetal} for a slightly different data set. Table \ref{summarytable_rank} presents ranks rather than ratings to facilitate comparisons across the methods. According to \citet{varinetal}, there is ``diffuse opinion'' among statisticians that the most prestigious statistics journals are, in alphabetical order, \textit{Annals of Statistics, Biometrika,} the \textit{Journal of the American Statistical Association} and the \textit{Journal of the Royal Statistical Society}, Series B. Accordingly, they argue that a good rating method will put them near the top. These ``big four'' are the gray lines in Table \ref{summarytable_rank}.

We find that PageRank depends heavily on a journal's pattern of out-citations. Although it ranks the ``big four'' journals at the top, it places \textit{Statistics in Medicine} (StMed), \textit{Journal of Statistical Planning and Inference} (JSPI), and \textit{Computational Statistics and Data Analysis} (CSDA) in positions six through eight, though they are ranked lowely by most other methods. These journals have the three highest out-citation counts in our data, and are among the most prolific citers of the top four journals. However, their ratios of in- to out-citations rank 20th, 30th, and 35th. Eigenfactor behaves similarly, with some differences reflecting its use of normalized data. (Eigenfactor is strongly correlated with PageRank, $0.91$, as shown in Table \ref{correlation_table}.) These results affirm PageRank and Eigenfactor as better measures of centrality or activity than importance, influence or prestige.

Impact Factor ranks some journals much higher than all other methods, reflecting its valuation of influence outside statistics. For example, the \textit{Journal of Statistical Software} (JSS) ranks 4th and \textit{Environmental and Ecological Statistics} (EES) ranks 14th, though it has the second-lowest in-citations in our data. On the other hand, the ``big four'' journals Bka and JASA are ranked 11th and 8th. The Impact Factor ratings are most strongly correlated with Article Influence ($0.87$, see Table \ref{correlation_table}). The similarity is somewhat surprising given the different methodology to arrive at the two ratings, but not unfounded. Both are normalized by articles per journal and are calculated using all citations, not just ones from the $47$ journals in our data set.  %I checked and pagerank calculated on normalized data and just the 47 jounals is pretty similar to Eigenfactor.
They share some seemingly anomalous rankings, such as \textit{Statistical Science} placing 2nd and 6th respectively. We can consider whether a high ranking for \textit{Statistical Science} is desirable. The journal's founding editor stated that a central goal of the journal is ``presenting the full range of contemporary statistical thought at a modest technical level accessible to the wide community of practitioners, teachers, researchers and students of statistics and probability'' \citep{degroot86}. As a review journal, it is well connected to top journals (confirmed by PageRank and Eigenfactor ranking it 13th), and it has relatively few articles which boosts its ranking when normalizing by article count. However, it is not likely to publish cutting-edge research, and its in-citation to out-citation ratio ranks 24th in our data. This suggests that it should not score so highly in a ranking of academic importance or influence. The visualizations provided by the latent space model help to further explain the position of \textit{Statistical Science} which will be revisited below.

The Latent Space and quasi-Stigler rankings are very similar (correlation $0.99$, see Table \ref{correlation_table}) and seem to provide the best measures of influence or importance in the field. They rank the ``big four'' journals in the top four positions, the \textit{Journal of Statistical Software} 42nd, and \textit{Statistical Science} 19th and 18th respectively. On the other hand, the methodological journal \textit{Scandinavian Journal of Statistics} (SJS) is highly ranked by both, at 6th and 8th respectively. SJS states its mission as ``reporting significant and innovative original contributions to statistical methodology, both theory and applications'' \citep{SJS}. \citeauthor{varinetal} use data from the UK Research Assessment Exercise (RAE), a periodic evaluation of UK university departments, as an external check on the quasi-Stigler rankings. They find some evidence that the quasi-Stigler model provides stronger correlation to RAE assessment of research quality than other methods. Details of that comparison, and its many caveats, are found in Section 6 of \citet{varinetal}.

\subsubsection{Comparison of Latent Space and Quasi-Stigler Model Output}\label{Comparison1}

As the quasi-Stigler and latent space models emerge as the best suited to our ranking task, we compare their results most closely. Figure \ref{fig:r latent2_stigler} (left) plots the compared ranks, with lighter labels for larger differences in rank. Three is the highest observed difference. However, the underlying differences in scores are very small, as shown in the right panel of Figure \ref{fig:r latent2_stigler}. Figure \ref{fig:r latent2_joy} confirms that the small differences in rank are not significant given the uncertainty in the estimated scores. Where a difference of one to three in the rankings translates to a meaningful probability of different scores the rankings from the two methods agree.
 
<<r latent2_stigler, eval = T, echo = F, cache = T, warning = F, message = F, fig.height = 4, fig.width = 7, results = 'hide', dependson= c("setup", "latent_sr2"), fig.cap = 'Left: Latent space vs. quasi-Stigler rankings. Better-ranked journals are at the top right, corresponding to higher numbers. Right: Comparison of scores rather than rankings. Lighter labels means larger differences (maximum rank difference is 3).'>>=

par(mfrow = c(1,2))
par(mai = c(.8,.8,.8,.4))
# compare ranks ####

srs2 = data.frame(quasi.Stigler = fit.table2$quasi,
             latent_space = latent.srp2.init.r$mkl$receiver -latent.srp2.init.r$mkl$sender)
rownames(srs2) = Cnet%v%"vertex.names"
srs2b = srs2
srs2b[,1] = rank(srs2b[,1])
srs2b[,2] = rank(srs2b[,2])
srdiff = srs2b[,1]-srs2b[,2]; #latent space - stigler.

## plot rank comparison ####
cr = grDevices::colorRampPalette(c("black", "gray"))( 4 )
col1 = rep(cr[1], 47)
col1[abs(srs2b[,1]-srs2b[,2]) >.5 ] = cr[2]
col1[abs(srs2b[,1]-srs2b[,2]) >1.5 ] = cr[3]
col1[abs(srs2b[,1]-srs2b[,2]) >2.5 ] = cr[4]

col1 = abs(srs2b[,1]-srs2b[,2])
rc = ggplot(data = srs2b, aes(x = quasi.Stigler, y = latent_space,
                         label = rownames(srs2b), col = col1)) +
    geom_text(angle = -45, size = 2.5) + 
    scale_color_gradient(low = "black", high = "gray", guide = F) + 
    theme_bw() +
    ylab("2D Latent Space") +
    ggtitle(label = "Rank Comparison")

sc = ggplot(data = srs2, aes(x = quasi.Stigler, y = latent_space,
                         label = rownames(srs2b), col = col1)) +
    scale_color_gradient(low = "black", high = "gray", guide = F) + 
    geom_point() +
    theme_bw() +
    ylab("2D Latent Space") +
    ggtitle(label = "Score Comparison")

cowplot::plot_grid(rc, sc)
@

<<r latent2_joy, eval = T, echo = F, cache = T, warning = F, message = F, fig.pos='t!', fig.height = 7, fig.cap = 'Posterior distributions of latent space score. Most small differences in ratings are not signficiant.'>>=
library(ggplot2)
library(ggjoy)

# scores:
latent2 = latent.srp2.init.r$mkl$receiver - latent.srp2.init.r$mkl$sender

# Posterior distribution of scores:
quantiles2 = apply(latent.srp2.init.r$sample$receiver - latent.srp2.init.r$sample$sender,
              2, quantile, seq(0,1,length.out = 101))
o = order(quantiles2[51,])
quantiles2 = quantiles2[,o]
tmp = data.frame(score = as.vector(quantiles2), node = as.factor(rep(1:47, each = 101)))

# Plot
ggplot(tmp, aes(x = score, y = node)) + geom_joy() + 
  ggtitle("Posterior Distributions of Latent Space Scores") +
  scale_y_discrete(name ="journal & point estimate",
                   labels= apply(cbind(rownames(Cmatrix)[o], sort(round(latent2, 2))),
                                 1, paste, collapse = "  "))

@

Figure \ref{fig:r latent2_centipede} shows that ratings uncertainty is similar between the two models. Point estimates from each model are displayed intervals of $1.96$ estimated standard deviations in either direction. On the left, the variances of the latent space scores are calculated from a sample of 5000 draws from the posterior distribution of parameters stored during MCMC estimation. On the right, the longer intervals are calculated from standard errors extracted from the scaled covariance matrix of the model. The interval for American Statistician (AmS) is missing because its coefficients were fixed at zero for indentifiability. The interior intervals are 1.96 quasi-standard errors (QSE) in each direction. These ``comparison intervals" are analogous to those in Figure 4 of \citeauthor{varinetal}. We see that they are smaller and more variable than the true standard error intervals. The justification by \citeauthor{varinetal} to present uncertainty through quasi-standard errors is that they can be listed alongside estimates in a table, and allow a familiar Pythagorean estimate of the standard error of a difference of two export scores.  However, in a centipede plot as shown, the true standard errors are just as compact and easy to compare, and reveal that the uncertainty in scores is roughly equivalent between the two models. Under both models, \textit{Stata Journal} (StataJ) has the largest standard error, which can be explained by the fact that it has by far the fewest in and out citations. As expected, standard error of scores and citation counts are inversely correlated.

The near identical rankings from these two models indicate that the positons in the latent space model are accurately accounting for the total citations between pairs of journals. While the quasi-Stigler model is conditioned on those totals, in the latent space model they are mostly explained by the positions, which exert the only dyad-specific symmetric effects. The positions provide additional insight to what drives those totals. A major advantage of the latent space model is the output visualization, which we explore in the next section.

<<r centipede_function, eval = T, cache = T, echo = F>>=
centipede.plot <- function (segs, mct = "mean", lower.limit = "std.error", upper.limit = lower.limit, 
    left.labels = NULL, right.labels = NULL, sort.segs = TRUE, 
    main = "", xlab = NA, pch = 21, vgrid = NA, hgrid = NA, gridcol = "lightgray", 
    left.labels.col = 1, right.labels.col = 1,
    mar = NA, col = par("fg"), bg = "green", cex = NULL, ...) 
{
    if (missing(segs)) {
        cat("Usage: centipede.plot(segs,...)\n\twhere segs is a dstat object")
        stop("or a matrix of midpoints and limits")
    }
    if (is.list(segs)) {
        if (all(lapply(segs, is.numeric))) 
            segs <- get.segs(segs, mct = mct, lower.limit = lower.limit, 
                upper.limit = upper.limit)
        else stop("If segs is a list, all the components must be numeric")
    }
    if (class(segs) == "dstat") {
        midpoint <- "mean"
        if (lower.limit == "var") {
            if (rownames(segs)[2] == "var") 
                ll <- segs[1, ] - segs[2, ]
            if (rownames(segs)[2] == "sd") 
                ll <- segs[1, ] - segs[2, ] * segs[2, ]
        }
        if (upper.limit == "var") {
            if (rownames(segs)[2] == "var") 
                ul <- segs[1, ] + segs[2, ]
            if (rownames(segs)[2] == "sd") 
                ul <- segs[1, ] + segs[2, ] * segs[2, ]
        }
        if (lower.limit == "sd") {
            if (rownames(segs)[2] == "var") 
                ll <- segs[1, ] - sqrt(segs[2, ])
            if (rownames(segs)[2] == "sd") 
                ll <- segs[1, ] - segs[2, ]
        }
        if (upper.limit == "sd") {
            if (rownames(segs)[2] == "var") 
                ul <- segs[1, ] + sqrt(segs[2, ])
            if (rownames(segs)[2] == "sd") 
                ul <- segs[1, ] + segs[2, ]
        }
        if (lower.limit == "std.error") {
            if (rownames(segs)[2] == "var") 
                ll <- segs[1, ] - sqrt(segs[2, ])/sqrt(segs[3, 
                  ])
            if (rownames(segs)[2] == "sd") 
                ll <- segs[1, ] - segs[2, ]/sqrt(segs[3, ])
        }
        if (upper.limit == "std.error") {
            if (rownames(segs)[2] == "var") 
                ul <- segs[1, ] + sqrt(segs[2, ])/sqrt(segs[3, 
                  ])
            if (rownames(segs)[2] == "sd") 
                ul <- segs[1, ] + segs[2, ]/sqrt(segs[3, ])
        }
        segs <- rbind(segs[1, ], ll, ul, segs[3, ])
    }
    segdim <- dim(segs)
    if (sort.segs) {
        seg.order <- order(segs[1, ])
        segs <- segs[, seg.order]
    }
    else seg.order <- 1:segdim[2]
    oldpar <- par("mar")
    #if (is.na(mar[1])) 
    #    mar <- c(4, 6, 1 + 2 * (nchar(main) > 0), 5)
    #par(mar = mar)
    plot(x = c(min(segs[2, ]), max(segs[3, ])), y = c(1, segdim[2]), 
        main = main, xlab = "", ylab = "", type = "n", axes = FALSE, 
        ...)
    box()
    if (!is.na(vgrid[1])) 
        abline(v = vgrid, lty = 1, col = gridcol)
    if (is.null(hgrid)) 
        abline(h = 1:segdim[2], lty = 2, col = gridcol)
    else if (!is.na(hgrid[1])) 
        abline(h = hgrid, lty = 2, col = gridcol)
    axis(1, cex.axis = cex)
    arrows(segs[2, ], 1:segdim[2], segs[3, ], 1:segdim[2], length = 0.05, 
        angle = 90, code = 3, col = col)
    points(segs[1, ], 1:segdim[2], pch = pch, col = col, bg = bg)
    if (is.null(left.labels)) {
        left.labels <- colnames(segs)
        if (is.null(left.labels)) 
            left.labels <- paste("V", seg.order, sep = "")
    }
    else left.labels <- left.labels[seg.order]
    plot.limits <- par("usr")
    mtext(left.labels, 2, line = 0.2, at = 1:segdim[2], adj = 1, 
        las = 1, cex = cex, col = left.labels.col)
    #if (is.null(right.labels)) 
    #    right.labels <- paste(round(segs[1, ], 2), "(", segs[4, 
    #        ], ")", sep = "")
    #else 
    right.labels <- right.labels[seg.order]
    mtext(right.labels, 4, line = 0.2, at = 1:segdim[2], adj = 0, 
        las = 1, cex = cex, col = right.labels.col)
    #if (is.na(xlab)) 
    #    xlab <- paste("| -", rownames(segs)[2], "-", rownames(segs)[1], 
    #        "-", rownames(segs)[3], "- |")
    if (!is.na(xlab)) 
        mtext(xlab, 1, line = 2)
    par(oldpar)
    invisible(segs)
}
@

<<r QS_sim_CI, eval = F, cache = T, echo = F, results = 'hide', warning = F>>=

# "True SE vs. Simulated 95% Intervals"
# No real discrepancy between simulated and exact, but the sampling method may be useful later, e.g. for joy plot

# Simulated CI Method ####

   # to get a predicution under the model we 
   # we need to draw from 47^2 - 47 (for the diag)
   # independent quasi-binomials with P, N as below
   # variance is d * N * P * (1-P)
   #
   # To simulate from a closely related distribution with desired mean and variance, we use the beta-binomial with appropriately set shape parameters. Results are very similar to using true SE, as shown below.

   # We generate data with the prescribed mean and overdispered variance, and repeatedly fit the export scores (for which we may use the `glm` function in the `stats` package or the `BTm` function in te `BradleyTerry2` package used by @varinetal, since the original formulaton of the Quasi-Stigler models citation counts as overdispersed binomial distributions.
   # $$E(C_{ij}) = t_{ij}\pi_{ij}),$$
   # $$var(C_{ij}) =  \phi t_{ij}\pi_{ij}(1 - \pi_{ij}),$$
   # where, given the transposed citation matrix notation in this paper
   # $\pi_{ij} = \frac{exp(u_j - u_i)}{1 + exp(u_j - u_i)} = logit^{-1}(u_j - u_i)$. 
 
# 1 Use beta-binomial - Setup #### 
      # roughly: introduces dependence in pi's which increases variance
      # we can adjust alpha and beta to achieve the QB mean and var

#using the BradleyTerry output instead of glm to ensure comparability
library(boot) #for inv.logit
library("extraDistr") #for rbern
d = phi
P = inv.logit(x1 %*% c(0, fit$coefficients)) 
#or inv.logit(x1 %*% c(0, (g1$coefficients)[2:47]))
#or P = g1$fitted.values
N = g1$prior.weights

# 2 set alpha and beta to agree with above mean and var: ####
mean1 = N*P
var1 = d*N*P*(1-P)
B = (1-P)/P
D = d*P*(1-P)
alpha = (N*B - D*(1+B)^2)/(D*(1 + B)^3 - (B+B^2))
beta = alpha*(1-P)/P
mean2 = N*alpha/(alpha + beta) 
var2 = N*alpha*beta*(alpha + beta +N)/((alpha + beta)^2 * (alpha + beta +1)) #should agree with mean1 for N >= 2
#special cases for N = 0 or 1 !!

#test comparison
#plot(dbinom(0:11, size = 11, prob = P[2]), type = "b")
#points(dbbinom(0:11, size = 11, alpha = alpha[2], beta = beta[2]), col = 2, type = "b")

# 3 simulate ####

nsim = 5000
g = matrix(0, 47, nsim)

for (i in 1:nsim) {
  sample1 = rep(0, length(N))
  for (j in 1:length(N)) {
    #if (N[i]==0) {return(0)}
    if (N[j]==1) {sample1[j] = rbern(1, P[j])}
    if (N[j] > 1) {sample1[j] = rbbinom(1, size = N[j], 
                alpha = alpha[j], beta = beta[j])}
  }
  y1 = sample1/Tmatrix[which(lower.tri(Tmatrix))]
  y1[is.nan(y1)]=0

  #fit model (can use glm or Bradley terry)
  #Ymatrix = matrix(y1, 47, 47, byrow = T)
  #rownames(Ymatrix) = colnames(Ymatrix) = rownames(Cmatrix)
  #Ydata <- countsToBinomial(Ymatrix)
  #g[,i] <- c(0,BTm(outcome = cbind(win1, win2),
  #                  player1 = player1,
  #              player2 = player2,
  #              data = Ydata)$coefficients)
  g[,i] = glm(y1~x1-1,family = quasibinomial(link="logit"), weights =   (Tmatrix)[lower.tri(Tmatrix)])$coefficients
}

g[1,] = 0

# 4 centipede plot ####

#original 
#centipede.plot(t(centipede.qse), vgrid = c(-1,0,1,2), cex = .7, 
#               right.labels = round(fit.table2$quasi, 2),
#               bg = "blue", main = "Quasi-Stigler")

#Beta-Binomial vs. SE
shift = mean(apply(g, 1, mean))
centipede.sim = cbind(apply(g, 1, mean), apply(g, 1, quantile, .025), apply(g, 1, quantile, .975)) - shift

centipede.plot(t(centipede.se), vgrid = c(-1,0,1,2), cex = .7, 
               right.labels = round(centipede.se[,1], 2), 
               left.labels = rownames(fit.table2), 
               bg = c("red"), col = c("red"),
               main = "True SE vs. Simulated 95% Intervals",
               xlim = c(-2, 2.5))
par(new=TRUE)
centipede.plot(t(centipede.sim), cex = .7,
               bg = c("green"), col = c("green"),
               left.labels = " ",
               right.labels = " ",
               xlim = c(-2, 2.5))
legend("bottomright", legend = c("SE", "SIM"), col = c("red", "green"), pch = 16)

@

<<r SE_vs_LATENT, cache = F, eval = F, echo = F, results = 'hide', warning = F, fig.keep = 'last', fig.height = 10>>=

#True SE for quasi-Stigler vs. Intevals vs. Latent Space.#Pretty comparable overall. StataJ's true SE interval is noticeably larger than others. This is likely due to the fact that it has fewer observed citations (in and out) than all other journals.

latent.srp2 <- readRDS("~/Documents/citation/Sunbelt/latent_srp2R.RDS")

#latent space centipede ####

# have to be careful with centipede plot now because
# order(centipede.se[,1]) != order(centipede.lat[,1])

# use seperate plots

par(mfrow = c(1,2))
latent.model = latent.srp2
sd2 = apply(latent.model$sample$receiver - latent.model$sample$sender, 2, sd)
latent2 = latent.model$mkl$receiver - latent.model$mkl$sender

centipede.lat = cbind(latent2, latent2 - 1.96*sd2, latent2 + 1.96*sd2) + 
    max(centipede.se[,1]) - max(latent2)
    #adding a shift so they align in the plot!
rownames(centipede.lat) = rownames(Cmatrix)

centipede.plot(t(centipede.lat), vgrid = c(-1,0,1,2), cex = .7, 
               right.labels = round(centipede.lat[,1], 2),
               left.labels = rownames(fit.table2),
               bg = "green", col = "green",
               main = "Latent Space")

centipede.plot(t(centipede.se), vgrid = c(-1,0,1,2), cex = .7, 
               right.labels = round(centipede.se[,1], 2),
               left.labels = rownames(fit.table2),
               bg = "red", col = "red",
               main = "True SE")

#keep seperate names

par(mfrow = c(1,1))
centipede1 = rbind(centipede.lat, centipede.se)
centipede1 = cbind(centipede1, c(rep(1, 47), rep(2, 47)))
centipede1 = centipede1[order(centipede1[,1]), ]
centipede.plot(t(centipede1[,1:3]), vgrid = c(-1,0,1,2), cex = .5, 
               left.labels = rownames(centipede1[,1]),
               right.labels = round(centipede1[,1], 2),
               left.labels.col = centipede1[,4],
               right.labels.col = centipede1[,4],
               bg = centipede1[,4], col = centipede1[,4],
               main = "True SE and Latent Space",
               sort.segs = F)
legend("bottomright", legend = c("SE", "LS"), col = c(2, 1), pch = 16)
@

\subsection{Visualization of Latent Space Journal Rankings} \label{Visualization}

Figure \ref{fig:r latent_sr2_plot} (top) shows estimated MKL positions, as described in Section \ref{MCMC}. (For more details on this choice see \citet{shortreed06}.) %shortreed06: heuristically, posterior mean graph is closer to the true than oberved graph due to averaging and use of prior info.
The size of the nodes is scaled to the estimated scores. The coloring and cluster labels for the nodes in both panels of Figure \ref{fig:r latent_sr2_plot} are based on the hierarchical clustering of \citet{varinetal}. Although there is no clustering term in our latent space model, the estimated positions are consistent with these clusters. (Some labels are difficult to read, but this is addressed by the dynamic plot referenced below.) The bottom panel of Figure \ref{fig:r latent_sr2_plot} shows a sample of 1000 posterior draws of positions, visualizing the uncertainty in the estimated positions. Although individual journal positions are variable, the clusters occupy discernible areas. The plot shows how they fit together and provides more information than discrete labels. For example the \textit{Journal of Biopharmaceutical Statistics} is most deeply embedded in the applied/health cluster, while \textit{Statistical Science} is on the border and in fact should be classified with the review journals it lies near. (We the use of latent space visualization to identify mislabeled classes in Section \ref{Example2}.) The irregular shapes of the clusters caution against applying the latent space clustering model of \citet{handcock07}, in which positions given clusters have spherical Gaussian distributions. 

<<r latent_sr2_plot, eval = T, cache = T, dependson= c("setup", "setup2", "latent_sr2", "setup_jrss"), echo = F, fig.width = 6, cache = T, warning=F, message=F, fig.cap= 'Estimated journal positions from the two-dimensional latent space model. Top: Point estimates with node size scaled to receiver minus sender coefficient. Bottom: Sample of positions from the model. Colouring is due to the hierarchical clustering of Varin et al. '>>=


# to correspond to visNetwork
library(scales)
alpha2 <- 0.6
color1 <- c("deepskyblue3","gold", "red", "green", "deeppink", "darkorchid4", "orange", "black")
Cnet%v%"color" = color1[cutree(journals.cluster, h = 0.6)]
write.csv(latent.srp2.init.r$mkl$Z, file = "~/Documents/citation/latent_ranking/latent_srp2_init_r_Z.csv")

# plot window
par(mai = c(.1,.1,.1,.1))
#layout(matrix(c(1,1,1,2,2,1,1,1,2,2,1,1,1,2,2), 3, 5, byrow = TRUE), respect = T)
par(mfrow = c(2,1))

#### position plot ####
vc2 <- (latent.srp2.init.r$mkl$receiver - latent.srp2.init.r$mkl$sender)/2+1
col2 <- alpha(color1[cutree(journals.cluster, h = 0.6)], alpha2)
plot(latent.srp2.init.r$mkl$Z, col = col2, cex = vc2, pch = 16,
     bty="n", yaxt="n", xaxt="n")
text(latent.srp2.init.r$mkl$Z, labels = rownames(Cmatrix), cex = .5, pos = 3, offset = .3)
legend("topleft", col = alpha(color1, alpha2), pch = 16, legend=c("review", "general", "theory/method", "appl./health", "computational","eco./envir.", "JSS", "StataJ"), cex=0.7, box.col=0)

####  cloud/uncertainty plot  ####
n = 47
N = 1000
p = latent.srp2.init.r[["sample"]][["Z"]]
s = sample(5000, N)

#null plot:
plot(latent.srp2.init.r$mkl$Z, xlab = NA, ylab = NA, vertex.col=0, edge.col=0, 
           plot.vars=F, suppress.axes=T, bty="n", yaxt="n", xaxt="n", type ="n",
           xlim = c(-4,4), ylim = c(-3,5), main = NA)

#add points
for (i in 1:N) {
  points(p[s[i],,], col = col2, pch = 15, cex = .2)
}

@

The citation network is too dense to display network edges in a static plot. However, using the \pkg{visNetwork} package we render a dynamic plot of the citation network to explore its connections. A version of the plot is included as an html file in the supplementary material, and is available on the author's website (\url{http://www.stat.ucla.edu/~jane.carlen/pages/citation_net.html}). Because of the density of the network, edges in the dynamic visualization are only shown if they account for at least three percent of a journal's out-citations, and their width when highlighted is scaled to that percentage. Rankings based on the latent space model are reported next to the journal titles in the drop-down menu on the left and in the hover text. Coloring of highlighted edges is determined by the cluster of the originating node, the same clusters as in Figure \ref{fig:r latent_sr2_plot}.

<<r latent_sr2_interactive, eval = F, results = 'hide', dependson= c("setup", "latent_sr2", "setup_jrss", "latent2_stigler"), fig.keep='last', echo = F, fig.height=5, fig.width=6, cache = T, warning=F, message=F>>=

# setup ####

library(visNetwork)
library(igraph)
#insertSource("~/Documents/citation/latent_ranking/visIgraph.R",
#             package = "visNetwork", functions = "visIgraph")
#insertSource("~/Documents/citation/latent_ranking/visIgraphLayout.R",
#             package = "visNetwork", functions = "visIgraphLayout")


# data ####
nodes <- data.frame(id = 1:47, 
                    label = Cnet%v%"vertex.names",
                    #title = Cnet%v%"vertex.names", #for selection dropdown
                    title = paste(Cnet%v%"vertex.names", 48 - srs2b[,2]), #for tooltip
                    value = vc2, #conveys node size, on a scale from 0-1
                    #color.highlight.background = "red",
                    group = rep((cutree(journals.cluster, h = 0.6))))


edges <- data.frame(from=data.frame(as.edgelist(Cnet))$X1, 
                    to=data.frame(as.edgelist(Cnet))$X2)
                    #value = Cnet%e%'citations'

cite_igraph <- graph.data.frame(edges, directed=TRUE, vertices=nodes)
Z = as.matrix(read.csv("~/Documents/citation/latent_ranking/latent_srp2_init_r_Z.csv")[,2:3])
Z<- -Z[ ,c(2,1)] #to preserve orientaiton in paper

#fewer edges
# Cmatrix.norm = t(Cmatrix)/citing #entries are % of i's citations to j (column); rows sum to 1; 'citing' is total out for each journal
strength = .03 #only include "strong receivers", e.g. receiver accounts for >.05 = 5% of sender's citations sent [different form the plot in `compare_clustered`]
#interesting plot with strength = .1 (100 edges remain)  
Cstrong = t(Cmatrix)
Cstrong[Cmatrix.norm<strength] = 0
#rowSums(Cstrong>0)
Cnet_strong = as.network(Cstrong, directed=T, matrix.type="a", ignore.eval=F,  names.eval="citations")

edges2 <- data.frame(from=data.frame(as.edgelist(Cnet_strong))$X1, 
                    to=data.frame(as.edgelist(Cnet_strong))$X2,
                    value = as.edgelist(Cnet_strong, as.sna.edgelist = T, attrname = "citations")[,3])

cite_igraph <- igraph::graph.data.frame(edges2, directed=TRUE, vertices=nodes)

# dynamic plot ####

visNetwork(nodes, edges2, main = "Statistics Journals", submain = "latent space positions") %>%
  visIgraphLayout(cite_igraph, layout = "layout.norm",
                  layoutMatrix = cbind(-Z[,2],Z[,1]), type = "full") %>%
  #visOptions(highlightNearest = list(enabled =TRUE, degree = 1)) %>%
  visNodes(#color = list(highlight = list(background = "green")), #not working as expected
           shape = "dot", #shape = "text"
           scaling = list(min = 3, max = 15),
           labelHighlightBold = TRUE,
           font= list(size = 20, color = "black", strokeWidth = 1)) %>%
  visOptions(highlightNearest = list(enabled = TRUE, degree = .5), #hover = TRUE doesn't work?
             nodesIdSelection = FALSE, 
             selectedBy = "title") %>% 
  visEdges(shadow = FALSE,
           #width = 1, to use width turn edge value off
           scaling = list(min = 1, max = 15),
           #selectionWidth = "function(x) {Cnet_strong%e%'citations';}",
           #scaling = list(min = 1, max = 10),
           arrows = list(to = list(enabled = FALSE, scaleFactor = 3),
                    middle = list(enabled = TRUE, scaleFactor = 1)),
           color = list(inherit = "from", highlight = "red", opacity = .03),
           hidden = F,
           smooth = list(type = "curvedCW")) #%>% visLegend()

  #turned these off bc interfering with edge inherit coloring
   # visGroups(groupname = "1", color = list(background = "blue")) %>%
   # visGroups(groupname = "2", color = list(background = "cyan")) %>%
   # visGroups(groupname = "3", color = list(background = "hotpink")) %>%
   # visGroups(groupname = "4", color = list(background = "yellow")) %>%
   # visGroups(groupname = "5", color = list(background = "grey")) %>%
   # visGroups(groupname = "6", color = list(background = "lavendar")) %>%
   # visGroups(groupname = "7", color = list(background = "red")) %>%
   # visGroups(groupname = "8", color = list(background = "green")) %>%

#saved as citation_net_revised.html        
@

Now we revisit the rankings of journals discussed in Secton \ref{Comparison}. The ``big four'' journals all draw citations widely from the network but tend to cite journals fairly nearby. In contrast, StMed, JSPI and CSDA, which are ranked highly by PageRank and Eigenfactor but not the latent space model, give and receive citations from a wide range of journals. JSS, which is ranked highly by Impact Factor and Article Influence but 42nd by the latent space model, only accounts for significant out-citations from one journal in the network, StataJ. \textit{Statistical Science} does draw citations from two top journals, but not at the rate of the hightest-ranked journals. Its in-citations have roughly the same span as its out-citations. The visualization reveals elements of how research flows through the network.

% \section{Data Expansion} - ON HOLD, this would take a lot of data scraping work and/or consent/release from JCR. Varin et al also don't have it.
% - \citet{varinetal} Data comes from 2010 Web of Science published by Thomson Reuters. Want to expand to include all of Statistics and Probability (?) and Mathematics, Applied ( 253 journals) and Agricultural, Economics and Policy (? 17 journals)
% Note JCR can give related journals, e.g.  http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RELATED_JOURNALS&rank=6&journal=CAN+J+AGR+ECON&query_new=true, and this could be another use of the network model

\subsection{Model Evaluation} \label{modeleval}

The latent space and quasi-Stigler models produce roughly equivalent journal rankings, but how well do they model the observed network? We consider several elements of the fit of our latent space model, especially as they compare to the quasi-Stigler model.

Figure \ref{fig:residuals} (left) displays sorted residuals on the scale of observed counts based on point estimates from the two-dimensinal latent space model, a Poisson sender-receiver model with no latent positions (D = 0), and the quasi-Stigler model. The quasi-Stigler model has the smallest residuals overall, which we expect since the model is constrained by dyad totals. The two-dimensional latent position model is a clear improvement on the same model without positions. The right plot of Figure \ref{fig:residuals} orders residuals by weight of the underlying edge. The $D=0$ model is systematically biased, as edges with lower citation counts are more likely to be underestimated, and heavier edges more likely to be underestimated. This pattern is slighly evident in the other two models, though much less severe.

Examining the underestimated edges with high edge weight confirms that they represent atypically strong connections between two journals, far more than they typically cite or are cited. This may be a result of the long tail distribution of citation counts, with a few papers that are relevant to specific journal sub-fields driving these values up, though we do not have access to the itemized counts to verify this. In addition, the model does not control for the fact that different sub-fields cite more heavily than others. %https://www.timeshighereducation.com/news/citation-averages-2000-2010-by-fields-and-years/415643.article
For example, the average computational journal as categorized by \citet{varinetal} has 419 out-citation in the network while the average ecological journal has only 115. A covariate could be added to the model to augment the expected counts within or between subfields. The value of journals that cite heavily outside of statistics, such as the Stata Journal which cites many economic journals, could also be downweighted. Alternately, if data for related fields such as economics and applied math becomes available (which it is not yet), we could employ such a covariate strategy between fields, or the clustering model of \citet{handcock07} if the network structure allows.  % In the next application we fit a latent space model to movie data that spans genres and different levels of connectivity.

% dimension choice? - mention consideration by other authors?

<<residuals, eval = T, cache = T, message =F, warning = F, results = 'hide', echo = F, dependson = c("glm"), fig.height = 4, fig.cap = 'Comparison of model residuals. Left: Residuals are ordered by size and only the range from -25 to 25 is shown to enhance detail. Right: Residuals ordered by weight of the corresponding edge.', fig.pos = 'H'>>=

# g1 (quasi stigler, or quassibinomial glm) ####

# under most likely graph | theta point estimate
# fitted.values for upper.tri: 2,1 3,1 ... 3,2, 4,2, ... 47,46
# this is because of how the response were listed in g1

#QSmat is the most likely graph (as matrix) under quasi-Stigler
QSmat = matrix(0, 47, 47)
QSmat[lower.tri(QSmat)] = (Tmatrix[lower.tri(Tmatrix)])*g1$fitted.values
QSmat = t(QSmat)
QSmat[lower.tri(QSmat)] = (Tmatrix[lower.tri(Tmatrix)])*(1-g1$fitted.values)
QSmat = t(QSmat)

g1.res = QSmat - t(Cmatrix); diag(g1.res) = NA

# latent model without positions ####
model = latent.srp0
R0 = predict(model) - model$model$Ym; diag(R0) = rep(NA, nrow(model$model$Ym))
#hist(R0, breaks = 100, col = "green", prob = T, ylim = c(0,.25), xlim = c(-50,50))

# latent model with 2-D positions ####
model = latent.srp2.init.r
R2 = predict(model, type = "mkl") - model$model$Ym; diag(R2) = rep(NA, nrow(model$model$Ym))
#hist(R2, breaks = 20, add = T, col = "red", prob = T, density = 30)

# other models with positions ####
#model = latent.srp1
#R1 = predict(model, type = "mkl") - model$model$Ym; diag(R1) = rep(NA, nrow(model$model$Ym))

#model = latent.srp3
#R3 = predict(model, type = "mkl") - model$model$Ym; diag(R3) = rep(NA, nrow(model$model$Ym))

#R = data.frame(residual = c(as.vector(g1.res), as.vector(R0),
 #                           as.vector(R2), as.vector(R1), as.vector(R3)),
  #             model = as.factor(c(rep("QS", 2209), rep("D = 0", 2209), rep("D = 2", 2209), 
   #                                rep("D = 1", 2209), rep("D = 3", 2209))),
    #           edgeweight = rep(as.vector(t(Cmatrix)), 5),
     #          order = c(rank(g1.res), rank(R0), rank(R2), rank(R1), rank(R3)))

# Summary ####
summary(as.vector(g1.res))
summary(as.vector(R0))
summary(as.vector(R2))
R = data.frame(residual = c(as.vector(g1.res), as.vector(R0), as.vector(R2)),
               model = as.factor(c(rep("QS", 2209), rep("D = 0", 2209), rep("D = 2", 2209))),
               edgeweight = rep(as.vector(t(Cmatrix)), 3),
               order = c(rank(g1.res, ties.method = "random"),
                         rank(R0, ties.method = "random"),
                         rank(R2, ties.method = "random")))
# Sorted Residual Plot ####
res_vs_index = ggplot(R, aes(x = order, y = residual, color = model)) + 
  geom_hline(yintercept = 0, col = "gray") +
  geom_point(size = .4) + ylim(-25,25) +
  theme_bw() +
  theme(legend.position="none") +
  ggtitle("Ordered Residuals")

#ggplot(data = R, aes(x = residual, fill = model, col = model)) +
 # geom_histogram(binwidth = c(1), position = "identity") +
  #theme_bw() + theme(legend.position = "none") + 
  #facet_wrap(~model, scales = "free_x")

# Residuals vs. Edge Weight Plot  ####
# not surprisingly, quasi fits best bc binomial model assumes totals (Tmatrix) known
res_vs_edge = ggplot(R, aes(x = edgeweight, y = residual, color = model)) + 
  geom_hline(yintercept = 0, col = "gray") +
  geom_point(size = .5, alpha = .8) +
  geom_smooth(method = "lm", se = T, size = .5) +
  theme_bw() + 
  guides(fill = F) +
  ggtitle("Residuals vs. Edge Weight") #+ facet_wrap(~model, scales = "free_x")

cowplot::plot_grid(res_vs_index, res_vs_edge, rel_widths = c(.75,1))
@

<<residuals2, eval = F, echo = F>>=
library(reshape)
Y = data.frame(t(Cmatrix))
Y = melt(Y); colnames(Y) = c("journal", "citations")
receiver_dist = ggplot(data = Y, aes(x = journal, y = citations, color = journal)) + geom_boxplot() + theme(legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("receiver distibutions")

Y = data.frame(Cmatrix)
Y = melt(Y); colnames(Y) = c("journal", "citations")
sender_dist = ggplot(data = Y, aes(x = journal, y = citations, color = journal)) + geom_boxplot() + theme(legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("sender distributions")

#ggplot(Y, aes(x = citations, y = journal)) + geom_joy() + xlim(0, 50)

cowplot::plot_grid(sender_dist, receiver_dist)
@

<<latent_binomial, eval = F, echo = F, cache = T, warning = F, results = 'hide'>>=

# the pi's fit by quasi-stigler are as good as when latent component added
# the fit z's for the binomial are very close to 0 
# one way we can interpret this as: total citations exchanged
# between two journals depends on positions, but given that total, 
# the specific taken by each can be modeled with just sender/receiver

theta = optim(c(a, b, B, Z),
                   Y = t(Cmatrix), d = 2, family = "binomial", llik2,
                   method = "BFGS", est = "Y", lower = -Inf,
                   control=list(maxit = 1000, fnscale = -1))
n = nrow(Y)
a = theta$par[1:n]
b = theta$par[(n+1):(2*n)]
B = theta$par[(2*n+1)]
Z = matrix(theta$par[(2*n+2):(2*n+1+d*n)], ncol = d, nrow = n)
Z_dist = dist2(Z)
l_lambda = t(b + t(a - Z_dist)) + B
#binomial
lambda = inv.logit(l_lambda); diag(lambda) = 0
res = Tmatrix * lambda - Y; diag(res) = NA 
#plot
plot(sort(as.vector(res)), type = "l", lwd = 2)
points(sort(as.vector(g1.res)), col = "blue", type = "l", lty = 2, lwd = 2)

# [removed] poisson.c
#lambda = exp(l_lambda); diag(lambda) = 0
#Tmatrix = Y + t(Y); diag(Tmatrix) = 0
#lambda[lambda > Tmatrix] = Tmatrix[lambda > Tmatrix]
#lambda[lower.tri(lambda)] = (Tmatrix - t(lambda))[lower.tri(lambda)]
#res = (lambda - Y); diag(res) = NA 

@

%2) GOF/value of added complexity BIC (bootstrap?)

% We can use the simulated graph stuff from sim_point_point to establish that the marginal distribution of data under the model is similar to the distribution of data given theta, which is poisson/exponential family. 

<<BIC, eval = F, echo = F>>=
summary(latent.srp0)$bic 
summary(latent.srp2)$bic #best overall
@


%3). Structure, reciprocity 

Another way to evalute model fit is to compare simulated graph statistics. Given the high reciprocity observed between journals and its influence on rankings, we are interested in whether this has been captured by the models. We employ a version of the reciprocity statistic defined by \citet{newman10}, adjusted for weighted networks. We consider both a normalized and unnormalized version to examine the impact of fixing dyad totals. 

$$\displaystyle reciprocity(Y) = \frac{\sum_{ij}Y_{ij}*Y_{ji}}{\sum_{ij}(\frac{Y_{ij}+Y_{ji}}{2})^2}$$

The value is zero for a completely imbalanced network and one for a perfectly symmetrical one. The denominator controls for the influence of variation in the dyad totals. The unnormalized version removes the denominator. Figure \ref{fig:structure_reciprocity_plot} (top) shows the observed reciprocity as a vertical line and simulated reciprocity based on posterior parameter distributions for the two Poisson models (D = 0 and D = 2), and based on the point estimate for the quasi-Stigler model. To simulate networks from the quasi-Stigler model we use a beta-binomial approximation with mean and variance matching the overdispersed binomial. The left panel shows normalized reciprocity while the right panel shows unnormalized values. 

The average reciprocity estimates are very similar for the two-dimensional and quasi-Stigler models. However, the variance of the two-dimensional model is slightly larger for normalized reciprocity and much larger for unnormalized (standard deviation of 13927 vs. 3628). As a result, the two-dimensional latent space model includes the observed value in its simulated range in both cases (p-values 0.003 (left) and 0.196 (right)), showing more appropriate model uncertainty. This difference is not due to the use of the posterior sample instead of a point estimate. Comparing the distribution for D = 2 shown in Figure \ref{fig:structure_reciprocity_plot} to one for draws from the MKL parameter estimates we find the variance from the point estimate to be only slightly smaller. The no-position Poisson model provides a lower estimate of normalized reciprocity since it lacks the symmetric effect of positions, but badly underestimates the unnormalized version, as it underestimates high edge values in general. 

<<sim_point_post, eval = F, echo = F, warning = F, message = F>>=

library(intergraph)

# the simulate.ergmm function randomly picks an mcmc sample to use for simulatution, i.e. simulating from the posterior distribution. ( models with no mcmc sample, e.g only "mle" fit, can't use simulate.ergmm)

# 1 simulate from point estimate - how much less varaibility? ####

model = latent.srp2.init.r
lambda.mkl = exp(model$mkl$receiver + t(model$mkl$sender -
                dist2(model$mkl$Z)) + model$mkl$beta); diag(lambda.mkl) = 0

nsim = 50
tmp = matrix(0,2209, nsim)
# average sets of graphs for each to smooth the poisson, i.e. nsim = nsim^2
for (i in 1:nsim) {
  tmp.j = matrix(0,2209, nsim)
  for (j in 1:nsim) {
    mat = matrix(rpois(2209, lambda), ncol = 47, nrow = 47); diag(mat) = NA
    tmp.j[,j] = mat - t(Cmatrix)
  }
  tmp[,i] = rowMeans(tmp.j)
}
tmp = apply(tmp, 1, quantile, c(.025,.25,.5,.75,.975), na.rm = TRUE)
tmp = tmp[,!is.na(tmp[1,])]
tmp = tmp[,order(tmp[3,])]
plot(tmp[3,s], type = "l")
points(tmp[1,s], type = "l")
points(tmp[5,s], type = "l")

# 2 simulate from graph posterior draw - slightly more variability (same as simulate function but this is for transparency) ####

nsim = 50
tmp1 = matrix(0,2209, nsim)
for (i in 1:nsim) {
  k = sample(1:length(model$sample$lpY), 1)
  lambda = exp(model$sample$receiver[k,] +
                 t(model$sample$sender[k,] -
                  dist2(model$sample$Z[k,,])) +
                 model$sample$beta[k])
  tmp1.j = matrix(0,2209, nsim)
  for (j in 1:nsim) {
    mat = matrix(rpois(2209, lambda), ncol = 47, nrow = 47); diag(mat) = NA
    tmp1.j[,j] = mat - t(Cmatrix)
  }
  tmp1[,i] = rowMeans(tmp1.j)
}
tmp1 = apply(tmp1, 1, quantile, c(.025,.25,.5,.75,.975), na.rm = TRUE)
tmp1 = tmp1[,!is.na(tmp1[1,])]
tmp1 = tmp1[,order(tmp1[3,])]
points(tmp1[3,s], type = "l", col = "red")
points(tmp1[1,s], type = "l", col = "red")
points(tmp1[5,s], type = "l", col = "red")

@
 
<<structure_reciprocity, eval = T, echo = F, cache = T, message =F, warning = F, results = 'hide', fig.height = 4>>=

reciprocity = function(A, normalize = T) {
 if(normalize) {sum(A*t(A), na.rm = T)/sum(((A+t(A))/2)^2, na.rm = T)}
  else {sum(A*t(A), na.rm = T)}
}
nsim = 1000

# 1. unnormalized ####

Q = reciprocity(t(Cmatrix), normalize = F)

# Poisson, QS
g = simulate.qs(g1, nsim = nsim)
#g = lapply(g, round)
tmp.qs = unlist( lapply(g, reciprocity, normalize = F))

# Poisson, D = 0
sim0 = simulate(latent.srp0, nsim) #draws from the posterior
tmp0 = unlist(lapply(sim0[[2]], function(x) {reciprocity(as.sociomatrix(x, attrname = "citations"), normalize = F)}) )

# Poisson, D = 2
sim2 = simulate(latent.srp2.init.r, nsim) #draws from the posterior
tmp2 = unlist(lapply(sim2[[2]], function(x) {reciprocity(as.sociomatrix(x, attrname = "citations"), normalize = F)}) )

# Poisson, D = 2, MKL point estimate
model = latent.srp2.init.r
lambda.mkl = exp(model$mkl$receiver + t(model$mkl$sender -
                dist2(model$mkl$Z)) + model$mkl$beta); diag(lambda.mkl) = 0
tmp2mkl = rep(0, nsim)
for (i in 1:nsim) {
  mat = matrix(rpois(2209, lambda.mkl), ncol = 47, nrow = 47); diag(mat) = 0 #0 instea of NA. NA causes all mod values to go to 0
  tmp2mkl[i] = reciprocity(mat, normalize = F)
}

# the simulate.ergmm function randomly picks an mcmc sample to use for simulatution, i.e. simulating from the posterior distribution.




# 2. normalized ####
Q.norm = reciprocity(t(Cmatrix), normalize = T)

# Poisson, QS
tmp.qs.norm = unlist( lapply(g, reciprocity, normalize = T))
tmp0.norm = unlist(lapply(sim0[[2]], function(x) {reciprocity(as.sociomatrix(x, attrname = "citations"), normalize = T)}) )
tmp2.norm = unlist(lapply(sim2[[2]], function(x) {reciprocity(as.sociomatrix(x, attrname = "citations"), normalize = T)}) )
tmp2mkl.norm = rep(0, nsim)
for (i in 1:nsim) {
  mat = matrix(rpois(2209, lambda.mkl), ncol = 47, nrow = 47); diag(mat) = 0 #0 instea of NA. NA causes all mod values to go to 0
  tmp2mkl.norm[i] = reciprocity(mat, normalize = T)
}

# the simulate.ergmm function randomly picks an mcmc sample to use for simulatution, i.e. simulating from the posterior distribution.



@

<<structure_reciprocity_plot, eval = T, echo = F, cache = T, message =F, warning = F, fig.height = 2, fig.width = 6, fig.pos = 'H', fig.cap = "Comparison of simulated reciprocity distributions based on 1000 simulations" >>=

rec.data = data.frame(model = c(rep("QS", nsim), rep("D = 0", nsim), rep("D = 2", nsim)), 
                      reciprocity = c(tmp.qs, tmp0, tmp2))
recplot1 = ggplot(rec.data, aes(x = reciprocity, fill = model)) +
  geom_histogram(position = "identity", bins = 40) +
  geom_vline(xintercept = Q, color = "gray", show.legend = T) + 
  geom_text(x=Q, label="observed", y = 250, colour="gray", angle=90, vjust = -.2, size=3) +
  geom_hline(yintercept = 0, col = "gray", size = .3) +
  theme_bw() +
  ggtitle("Reciprocity") +  labs(x = NULL)
  
rec.data = data.frame(model = c(rep("QS", nsim), rep("D = 0", nsim), rep("D = 2", nsim)), 
                      normalized_reciprocity = c(tmp.qs.norm, tmp0.norm, tmp2.norm))
recplot1.norm = ggplot(rec.data, aes(x = normalized_reciprocity, fill = model)) +
  geom_histogram(position = "identity", bins = 40) +
  geom_vline(xintercept = Q.norm, color = "gray", show.legend = T) + 
  geom_text(x=Q.norm, label="observed", y = 80, colour="gray", angle=90, vjust = -.2, size=3) +
  geom_hline(yintercept = 0, col = "gray", size = .3) +
  theme_bw() + 
  theme(legend.position = "none") +
  ggtitle("Normalized Reciprocity") + labs(x = NULL)

# Compare modularity distribution from simulating from MKL point estimate vs. posterior distribution
rec.data = data.frame(model = c(rep("D = 2", nsim), rep("D = 2, mkl", nsim)), 
                      reciprocity = c(tmp2.norm, tmp2mkl.norm))
recplot2.norm = ggplot(rec.data, aes(x = reciprocity, fill = model)) +
  geom_histogram(position = "identity", bins = 40) +
  geom_vline(xintercept = Q.norm, color = "gray", show.legend = T) + 
  geom_text(x=Q.norm, label="observed", y = 68, colour="gray", angle=90,
            vjust = -.2, size=3) +
  theme_bw() + facet_wrap(~model, scales = "fixed") + 
  theme(legend.position = "none") + 
  geom_hline(yintercept = 0, col = "gray", size = .3) +
  scale_fill_manual(values = c(hue_pal()(3)[2], hue_pal()(4)[4])) +
  labs(x = "Normalized Reciprocity")

rec.data = data.frame(model = c(rep("D = 2", nsim), rep("D = 2, mkl", nsim)), 
                      reciprocity = c(tmp2, tmp2mkl))
recplot2 = ggplot(rec.data, aes(x = reciprocity, fill = model)) +
  geom_histogram(position = "identity", bins = 40) +
  geom_vline(xintercept = Q, color = "gray", show.legend = T) + 
  geom_text(x=Q, label="observed", y = 68, colour="gray", angle=90,
            vjust = -.2, size=3) +
  theme_bw() + facet_wrap(~model, scales = "fixed") + 
  theme(legend.position = "none") + 
  geom_hline(yintercept = 0, col = "gray", size = .3) +
  scale_fill_manual(values = c(hue_pal()(3)[2], hue_pal()(4)[4])) +
  labs(x = "Reciprocity")

cowplot::plot_grid(recplot1.norm, recplot1, rel_widths = c(.8, 1), nrow = 1)

@

<<structure_reciprocity_stats, eval = F, echo = F >>=
sum(tmp2<Q)
sum(tmp2mkl<Q)
sum(tmp.qs.norm<Q.norm)
sum(tmp0.norm<Q.norm)
sum(tmp2.norm<Q.norm)
sum(tmp2mkl.norm<Q.norm)

mean(tmp.qs)
mean(tmp2)
mean(tmp2mkl)
mean(tmp.qs.norm)
mean(tmp2.norm)

sd(tmp.qs)
sd(tmp0)
sd(tmp2)
sd(tmp2mkl)
sd(tmp2.norm)
sd(tmp2mkl.norm)

@

<<structure_exp_trans, eval = F, echo = F, cache = T, message =F, warning = F, results = 'hide'>>=

#Leave out transitive structure section - the statistic doesn't seem to capture what we would be interested in regarding transitivity for these nets. Also odd that the basic model overestimates transitivity by this metric.

# Some experimental structure stats for hierarchy and transitivity.
# Probalby won't include

# hierarchy ####
# exphi is measure for each node (i) the weighted average of citations received for nodes (j) i is connected to
# weighted by normalized out-citations for i.
exphi <- function(mat) {
  v = ( mat*(1/rowSums(mat)) ) %*% colSums(mat)
  v = sort(v)
}

tmp2 = lapply(sim2[[2]], function(x) {
  exphi(as.sociomatrix(x, directed = T, attrname = "citations"))
})
qua2 = apply(matrix(unlist(tmp2), nrow = n, ncol = nsim), 1, quantile, c(.25, .95))

tmp0 = lapply(sim0[[2]], function(x) {
  exphi(as.sociomatrix(x, directed = T, attrname = "citations"))
})
qua0 = apply(matrix(unlist(tmp0), nrow = n, ncol = nsim), 1, quantile, c(.25, .95))

tmp.qs = lapply(g[[2]], function(x) {
  exphi(as.sociomatrix(x, directed = T, attrname = "citations"))
})
qua.qs = apply(matrix(unlist(tmp.qs), nrow = n, ncol = nsim), 1, quantile, c(.25, .95))

par(mfrow = c(1,3))
plot(exphi(t(Cmatrix)), type = "l", lwd = 3)
points(qua.qs[1,], type = "l", col = "blue")
points(qua.qs[2,], type = "l", col = "blue")
plot(exphi(t(Cmatrix)), type = "l", lwd = 3)
points(qua2[1,], type = "l", col = "red")
points(qua2[2,], type = "l", col = "red")
plot(exphi(t(Cmatrix)), type = "l", lwd = 3)
points(qua0[1,], type = "l", col = "green")
points(qua0[2,], type = "l", col = "green")
#points(exphi(QSmat), col = "blue", type = "l")

# transitivity ####
# exptrans measure the mean connectedness among the nodes that (i) is most connected to (determined by cutoff)
# not a great comparison since qs fixes total citations on a dyad.
exptrans <- function(Y, cutoff = 20) {
  N = nrow(Y)
  diag(Y) = rep(0, N)
  tmp = 1:N
  for(i in 1:N) {
    # mean %age inter-connection between journals strongest connected to i
     # i.e. the journals that send greatest % of their citation to i
    j = sort(Y[,i]/rowSums(Y), decreasing = TRUE)[1:cutoff]
    ind = which(Y[,i]/rowSums(Y)>=j[cutoff])
    tmp[i] = mean((Y/rowSums(Y))[ind,ind])
  }
  if (!is.null(row.names(Y))) names(tmp) = row.names(Y)
  return(tmp)
}

plot(sort(exptrans(t(Cmatrix), cutoff)), ylim = c(0,.06), type = "l")
points(sort(exptrans(predict(latent.srp0), cutoff)), col = "red", type = "l")
points(sort(exptrans(predict(latent.srp2), cutoff)), col = "green", type = "l")
points(sort(exptrans(predict(latent.srp2.h, type = "start"), cutoff)), col = "magenta", type = "l")
points(sort(exptrans(QSmat, cutoff)), col = "blue", type = "l")
@

\subsubsection{Sensitivity} \label{sensitivity}

<<hyperpriors, eval = F, cache = T, echo = F, results = 'hide', warning= F, message = F, fig.keep='none'>>=

# Which parameters could we adjust for more realistic priors?
# We consider putting narrower priors on the variance and intercept parameters

# Adjust the models ####

N = 47
sender.var.df = 2*3 #default 3 ** shrink sender range
receiver.var.df  = 2*3 #default 3 ** shrink receiver range
Z.var.df = 2*sqrt(N)  #default sqrt(N) ** shrink z range

prior.sender.var = .5 #default 1
prior.receiver.var = .5
prior.Z.var = N/32 #default N/8 ** shrink sigma_z range
beta.var = 1 #default 9

quantile(rinvchisq(100000, sender.var.df, prior.sender.var), probs = c(0.05, .95))
quantile(rinvchisq(100000, Z.var.df, prior.Z.var), probs = c(0.05, .95))

samp1 = rep(0, 500)
median1 = rep(0, length(samp1))
mean1 = rep(0, length(samp1))
N = 47
for (i in 1:length(samp1)) {
  # higher df condenses it
  # higher var moves mode from 0
  sender.var = rinvchisq(1, sender.var.df, prior.sender.var)
  receiver.var = rinvchisq(1, receiver.var.df, prior.receiver.var)
  Z.var = rinvchisq(1, Z.var.df, prior.Z.var)
  object$map = list(
    beta = rnorm(1, 0, sd = sqrt(beta.var)),
    sender = rnorm(N, 0, sqrt(sender.var)),
    receiver = rnorm(N, 0, sqrt(receiver.var)),
    Z = matrix(rnorm(N*d, 0, sqrt(Z.var)), nrow = N, ncol = d)
  )
  median1[i] = median(predict.lsqn(object, type = "rpois"), na.rm = T)
  mean1[i] = mean(predict.lsqn(object, type = "rpois"), na.rm = T)
}
Z_dist = dist2(object$map$Z)
summary(median1)
summary(mean1)

# BETTER, no non-zero derivatives
latent_qn2.h = lsqn(Y = Y, N = 47, D = 2, runs = 50, tol = .01,
     v_a = sender.var.df, v_b = receiver.var.df, v_z = Z.var.df,
     s2_a = prior.sender.var, s2_b = prior.receiver.var, s2_z = prior.Z.var,
     sigma2_B = beta.var ) 

latent.srp2.h = ergmm(Cnet ~ euclidean(d = 2) + rsender + rreceiver, 
                    response = "citations", family = "Poisson.log", seed = 30,
                    prior = ergmm.prior(sender.var.df = sender.var.df,
                                        receiver.var.df = receiver.var.df,
                                        Z.var.df = Z.var.df,
                                        sender.var = prior.sender.var,
                                        receiver.var = prior.receiver.var, 
                                        Z.var = prior.Z.var,
                                        beta.var = beta.var),
                    control = ergmm.control(burnin = 50000, interval = 500,
                                            sample.size = 5000, mle.maxit = 100,
                                            refine.user.start = F),
                    user.start = with(latent_qn2.h$map, list(Z=Z, sender=sender, receiver=receiver,
                                            beta = beta, sender.var = sender.var,
                                            receiver.var = receiver.var, Z.var = Z.var)),
                    verbose = 3)

# Analyze ####

model = latent.srp2.init.r
sd2 = apply(model$sample$receiver - model$sample$sender, 2, sd)
latent2 = model$mkl$receiver - model$mkl$sender
centipede1 = t(cbind(latent2, latent2 - 1.96*sd2, latent3 + 1.96*sd2))
colnames(centipede1) = Cnet%v%"vertex.names"

model = latent.srp2.h
sd.h = apply(model$sample$receiver - model$sample$sender, 2, sd)
latent.h = model$mkl$receiver - model$mkl$sender
centipede.h = t(cbind(latent.h, latent.h - 1.96*sd.h, latent3 + 1.96*sd.h))
colnames(centipede.h) = Cnet%v%"vertex.names"

par(mfrow = c(1,2))
centipede.plot(centipede1, vgrid = c(-1,0,1,2), cex = .7, right.labels = round(latent2, 2),
               bg = "red", main = "Original Hyperpriors")
centipede.plot(centipede.h, vgrid = c(-1,0,1,2), cex = .7, right.labels = round(latent.h, 2),
                bg = "red", main = "Adjusted Hyperpriors")
cor(latent2, latent.h)
cor(sd.h^2, sd2^2)

# Experimenting ####

#model_citeh = lsqn(Y, runs = 50, tol = .01, v_z = 1, s2_z = 10) #worst, Z.var too small
#model_cite.h = lsqn(Y, runs = 50, tol = .01, v_z = 20, s2_z = 10)
#model_cite.h2 = lsqn(Y, runs = 100, tol = .01, v_z = 10, s2_z = N/8, v_a = 1, s2_a = 1, v_b = 1, s2_b = 1)

#plot(model_cite.h2$map$Z, col = col2, pch = 16)



@

As with any Bayesian model we must consider the sensitivity of estimates to the assumptions contained in the prior structure and hyperprior values. However, we find such a strong correlation (0.999) between the rating scores resulting from the MLE and MKL estimates that there is little reason to suspect bias undue influence from the priors. Still, we consider shrinking the prior intercept variance to one, and adjustments to the hyperprior degrees of freedom and variances. This narrows the prior distributions on variance parameters to more realistic ranges based on previous results. The prior distributions on sender and receiver variances have middle 90 percent intervals of roughly .2 to 1.8 instead of .4 to 8.5, and for position variance 0.9 to 3.2 instead of 2.9 to 20. The impact on the results is trivial. The updates estimtes of scores and their variances have barely changed from the previous estimates (correlation > 0.99).

The quasi-Netwon estimation method is more sensitive to the hyperpriors, and we use the adjusted hyperprior values to produce final estimates.

\subsubsection{Comparison of Estimation Methods} \label{estimeval}

<< compare_latent_models, eval = T, echo = F, cache=T, results='asis', cache.comments = FALSE, warning= FALSE, dependson = c("latent_sr2_init_r, latent_sr2")>>=
mcmc.diagnostics(latent.srp2.init.r)

mcmc.diagnostics(latent.srp2)
results.table = data.frame(row.names = c("Quasi-Newton", "optim (L-BFGS-B)", "MCMC (MKL)", "MCMC.init.r (MKL)" ))
results.table$"Time (min)" = c("$<1$", "$<1$", round(t2.srp2 - t1.srp2), round(t2.init.r - t1.init.r))
results.table$"$l(Y|\\hat{\\theta})$" = as.character(round(
                                c(llik(latent_qn$map, Y = t(Cmatrix), est = "Y"), 
                                llik(latent.srp2.init.r$burnin.start, Y = t(Cmatrix), est = "Y"),
                                llik(latent.srp2$mkl, Y = t(Cmatrix), est = "Y"),
                                llik(latent.srp2.init.r$mkl, Y = t(Cmatrix), est = "Y"))))
results.table$"$l(\\hat{\\theta})$" = as.character(round(
                                c(llik(latent_qn$map, Y = t(Cmatrix), est = "theta"),
                                llik(latent.srp2.init.r$burnin.start, Y = t(Cmatrix), est = "theta"),
                                with(latent.srp2$mcmc.mle, llik(latent.srp2$mkl,
                                     Y = t(Cmatrix), sender.var = sender.var,
                                     receiver.var = receiver.var, Z.var = Z.var, est = "theta")),
                                with(latent.srp2.init.r$mcmc.mle, llik(latent.srp2.init.r$mkl,
                                     Y = t(Cmatrix), sender.var = sender.var,
                                     receiver.var = receiver.var, Z.var = Z.var, est = "theta")))))

results.table$sample = c("No", "No", "Yes", "Yes")
results.table$code = c("R", "C", "C", "C")
latent2 = latent.srp2.init.r$mkl$receiver - latent.srp2.init.r$mkl$sender
results.table$"Score Cor." = c(cor(latent2, latent_qn$map$receiver - latent_qn$map$sender),
                               cor(latent2, latent.srp2.init.r$burnin.start$receiver - 
                                            latent.srp2.init.r$burnin.start$sender),
                               cor(latent2, latent.srp2$mkl$receiver - latent.srp2$mkl$sender),
                               cor(latent2, latent.srp2.init.r$mkl$receiver - 
                                            latent.srp2.init.r$mkl$sender))

print(xtable(results.table, caption = "Estimation Methods", digits = 4, label = "results.table"),
      sanitize.text.function=function(x){x})

  # random initialization and direct optimization get best map results.
  # random initialization and no mcmc has highest graph probability, but in terms of ranks it's basically identical. and the positions are extremely similar.
  # mcmc doesn't really add to likelihood
  
est = "MAP"

with(latent.srp2.init.r$mcmc.mle, llik(latent.srp2.init.r$mkl, Y = t(Cmatrix), #use?
    sender.var = sender.var, receiver.var = receiver.var, Z.var = Z.var, est = est))

llik(latent.srp2.init.r$mcmc.mle, Y = t(Cmatrix), est = est)

llik(latent.srp2.init.r$mcmc.pmode, Y = t(Cmatrix), est = est)
  
llik(latent.srp2.init.r$burnin.start, Y = t(Cmatrix), est = est) #mle?

llik(latent.srp2.init.r$mcmc.mle, Y = t(Cmatrix), est = est)

llik(latent.srp2.init.r$mcmc.pmode, Y = t(Cmatrix), est = est)
   
with(latent.srp2.init.r.bfgs$mcmc.mle, llik(latent.srp2.init.r.bfgs$mkl,
                Y = t(Cmatrix), sender.var = sender.var, receiver.var = receiver.var, Z.var = Z.var, est = est))

llik(latent.srp2.init.r.bfgs$mcmc.mle, Y = t(Cmatrix), est = est)

llik(latent.srp2.init.r.bfgs$mcmc.pmode, Y = t(Cmatrix), est = est)

#plot(latent.srp2.init.r$mkl$Z, col = col2, pch = 16)
#plot(vegan::procrustes(latent.srp2.init.r$mkl$Z, latent.srp2.init.r$burnin.start$Z)$Yrot, col = col2, pch = 16)

  #these all look fine
  #mcmc.diagnostics(latent.srp2)
  #mcmc.diagnostics(latent.srp2.init.r)
  #mcmc.diagnostics(latent.srp2.init.r.sann)
  
  #same as sann
  #with(latent.srp2.init.r.bfgs, llik(t(Cmatrix), mkl$sender, mkl$receiver, mkl$beta, mkl$Z,  mcmc.mle$sender.var, mcmc.mle$receiver.var, mcmc.mle$Z.var,est = est))
  
  # best mcmc.mle estimate consistently a little workse than mkl
  # with(latent.srp2$mcmc.mle, llik(t(Cmatrix), sender, receiver, beta, Z,sender.var, receiver.var, Z.var, est = est))
  # with(latent.srp2.init.r.sann$mcmc.mle, llik(t(Cmatrix), sender, receiver, beta, Z, sender.var, receiver.var, Z.var, est = est))
  # with(latent.srp2.init.r.bfgs$mcmc.mle, llik(t(Cmatrix), sender, receiver, beta, Z, sender.var, receiver.var, Z.var, est = est))

 #even worse with #(latent.srp2, llik(Y, mkl$sender, mkl$receiver, mkl$beta, mkl$Z, sum(mkl$sender^2 + v_a*s2_a^2) / (N + 2 + v_a), sum(mkl$receiver^2 + v_b*s2_b^2) / (N + 2 + v_b), sum(as.vector(mkl$Z)^2 + v_z*s2_z^2) / (N*d + 2 + v_z), est = "MAP"))

@

Table \ref{compare_latent_models} compares the results for the two-dimensional Poisson latent space model with four different estimations techniques: 1) The quasi-Netwon method outlined in section \ref{QN}; 2) The limited-memory bounded quasi-Newton method implemented by the \code{optim} function from the \proglang{R} base package \pkg{stats}, which is the intermediate optimization method of \pkg{latentnet}; 3) MCMC estimation as implemented by \pkg{latentnet} 4) MCMC from \pkg{latentnet} with random initialization as used in quasi-Newton method 1.

- probabilities up to a constant. 
For MCMC methods we checked for convergence and appropriate MCMC interval and burn-in values using the \code{mcmc.diagnostics} function of \pkg{latentnet}. 
The MCMC estimation without random initialization (method 3) is much slower than with random initialization (method 4) because the burn-in period must be three times as long. Still either method could be sped up if the control parameters are perfectly chosen, but the process of selecting them would probably negate the time benefits. The MKL estimates are used for both MCMC methods and had higher probab

Results in previous sectios have all drawn on the MKL  presented the parameter estimate with the highest posterior likelihood. 

- although the quasi-Newton estimates were produced using different hyperpriors than the MCMC estimates, for consistency the 

Timing of computations was done in R 3.3.2 with a MacBookPro with 2.6 GHz Intel Core i5 processor with 8 GB 1600 MHz DDR3 memory without. Although not employed here, \pkg{latentnet} does allow for parallel processing of multiple MCMC chains. 

\section{Movie Rating and Genre Identification}\label{Example2}

In this section we apply latent space rating to a set of films with viewer-supplied star ratings. Film rating systems based on viewer ratings are biased by the fact that viewers do not choose movies to rate randomly, and they may skew high or low in their ratings. In addition, average ratings obscure the information provided by the volume of ratings for different films. Our method efficiently address those challenges. The concomitant visualizations also aid in genre detection and enhance our ability to explore and compare related films. We compare our results to user star averages, but focus our analysis on the value-added of the latent positions for exploring the network and for genre identification.  Through a dynamic network plot we increase the amount of data we can present. Movie ratings are extremely subjective, so without knowing detailed individual preferences the ability to explore a network of films may be more useful than finding ``correct'' ratings.

%See full code in movie_example.R

%1M Benchmark Data Set
%http://files.grouplens.org/datasets/movielens/ml-1m-README.txt
%Permalink: http://grouplens.org/datasets/movielens/1m/

\subsection{Data}\label{Data2}

Our data comes from the MovieLens data set \citep{movielens}, collected by the GroupLens Research Project at the University of Minnesota. It consists of about one million ratings of 3,952 movies from approximately 6,000 users who joined MovieLens in 2000. The data was released in 2003. Ratings are on a one-to-five integer scale with five being the best. Each user included has supplied at least 20 ratings.

To convert the data into a network format we aggregate differences in individual users' ratings to form a $3952 \times 3952$ ratings-difference matrix. To be explicit, entry $i, j$ in the matrix represents the sum, over all users who have rated movie $i$ and movie $j$, of positive values of $rating(j) - rating(i)$. (If $rating(i) > rating(j)$ the difference is added to entry $j,i$.) For example, if a user prefers movie $j$ to $i$ by one point, then one is added to entry $i, j$: $i$ ``sends'' a point to $j$. The corresponding network is positive-valued and directed. 
%note the data isn't quite coints, as the differences range between 1 and 4, but most are 1 or 2. Overdispersed?

To illustrate certain points without too much computational burden we restrict ourselves to a subset of the MovieLens data, retaining only movies assigned genre ``Action'', ``Crime'', ``Western'' or some combination therein. (Only two of the possible combinations are present in the data.) We remove a small number of isolates before modeling. The resulting network has 130 nodes and 11,393 edges.

\subsection{Latent Space Model}\label{Model2}

By modeling the network of differences in ratings, we capture the tendency for a movie to be frequently and consistently rated above movies that draw an overlapping audience. Code to implement our model in \pkg{latentnet} is included in the supplementary material.

%full movie net is saved as movie_net.rds
<<r movie_data, eval = T, echo = F, cache = T>>=
movie = readRDS("~/Documents/citation/latent_ranking/movie_output.RDS")
movie_net_acw = movie$movie_net_acw
movie_net_acw_full = movie$movie_net_acw_full
movie_net_watch_full = movie$movie_net_watch_full
vc.acw = movie$vc.acw
latent_acw2 = movie$latent_acw2
@

<<r movie_model, eval = F, echo = F, results = 'asis', highlight = F>>=
latent_acw2 = ergmm(movie_net_acw_full ~ euclidean(d=2) + rreceiver + rsender, 
             response = "ratings_diff", family = "Poisson.log",
             control = control.ergmm(pilot.runs = 4,  burnin = 500000, 
             interval = 100, sample.size = 10000), seed = 123)
@

%even with a very long burning (5mill, took about 6hrs with interval 500, sample 10000) the final map only increases by a few over initial direct optimization

<<r movie_model_r, eval = F, echo = F, results = 'asis', highlight = F, cache = T>>=

M = as.sociomatrix(movie_net_acw_full, ignore.eval = F, attrname = "ratings_diff")
N = nrow(M); n = N; D= 2; d = 2; 
v_z = sqrt(N); s2_z = N/8
Z_dist = dist2(M)
Z = cmdscale(Z_dist, k = D)
Z = Z/max(abs(Z))
sigma2_z = var(as.vector(Z))
a = rnorm(N)
b = rnorm(N)
sigma2_a = var(a)
sigma2_b = var(b)

latent_acw2.r = ergmm(movie_net_acw_full ~ euclidean(d=2) + rreceiver + rsender,
                      response = "ratings_diff", family = "Poisson.log",
                      control = control.ergmm(pilot.runs = 4,  burnin = 0,
                      interval = 100, sample.size = 1000), seed = 123,
                      user.start = list(Z = Z, sender = a, receiver = b, 
                                        sender.var = sigma2_a,
                                        receiver.var = sigma2_b,
                                        Z.var = sigma2_z))

llik(latent_acw2.r$mkl, Y = M, sender.var = latent_acw2.r$mcmc.mle$sender.var, 
     receiver.var = latent_acw2.r$mcmc.mle$receiver.var, Z.var = latent_acw2.r$mcmc.mle$Z.var)

@

<<r movie_model_r2, eval = T, echo = T, results = 'asis', highlight = F, cache = T>>=
llik(latent_acw2.r$mkl, Y = M, sender.var = latent_acw2.r$mcmc.mle$sender.var, 
     receiver.var = latent_acw2.r$mcmc.mle$receiver.var, Z.var = latent_acw2.r$mcmc.mle$Z.var)

@

<< latent_watch_init_r, eval = T, results = 'hide', echo = F, cache=T, cache.comments = FALSE, warning= FALSE>>=

W = as.sociomatrix(movie_net_watch_full, ignore.eval = F, attrname = "ratings_diff")
#random initation of sender and receiver, and scaling Z helps the model fit
D = 2; N = nrow(W)
Z_dist = dist2(t(W))
Z = cmdscale(Z_dist, k = D)
Z = Z/max(abs(Z))
a = rnorm(N) #rep(0, N) # #sender
b = rnorm(N) #rep(0, N) # #receiver

#I tried this with 50k, 500, 5k and the sampling step took >  24 hours, stopped it
#mle.maxit 50 is probably enough

latent.watch.init.r = ergmm(movie_net_watch_full ~ euclidean(d = 2) + rsender + rreceiver,
                              response = "ratings_diff", family = "Poisson.log", seed = 30,
                              tofit = c("mcmc", "mkl", "procrustes", "mle"),
                              control = ergmm.control(burnin = 50000, interval = 50,
                                                      sample.size = 1000,
                                                      mle.maxit = 100),
                              user.start = list(Z = Z, sender = a, receiver = b, beta = 0,
                                                sender.var = var(a),
                                                receiver.var = var(b),
                                                Z.var = var(as.vector(Z))))
@

<< latent_watch_mle, eval = T, results = 'hide', echo = F, cache=T, cache.comments = FALSE, warning= FALSE>>=

latent.watch.mle = ergmm(movie_net_watch_full ~ euclidean(d = 2) + rsender + rreceiver,
                              response = "ratings_diff", family = "Poisson.log", seed = 30,
                              tofit = c("mle"),
                              control = ergmm.control(mle.maxit = 100),
                              user.start = list(Z = Z, sender = a, receiver = b, beta = 0,
                                                sender.var = var(a),
                                                receiver.var = var(b),
                                                Z.var = var(as.vector(Z))))
@

There is a strong correlation of $0.94$ (or $0.975$ when weighted by the log of co-review counts) between a film's average rating and its ratings from the latent space model (receiver minus sender coefficient).
%?($x$ unweighted, $x$ when weighted by the logged counts of ratings).
Figure \ref{fig:r movie_compare} shows this correlation, plotting the latent space scores against the average ratings and labeling points by review counts for each film. The major outliers all have very low review counts, while films with high review counts fit closely in the linear trend. We take a closer look at a couple of the films that deviate from the trend but have more than $20$ reviews, highlighted in green. The corresponding films are, from left to right, \textit{Shaft in Africa (1973)} and \textit{Assassination (1987)}. These films have a potential ``cult'' following based on their lead actors, Richard Roundtree (as Shaft) and Charles Bronson respectively. That may boost some of the user reviews, but when comparative reviews are considered in the latent space model the derived rating is lower. 
%also #79 with 32 reviews, Wanted: Dead or Alice (1987). Based on a three-season television show that launched steve mcqueen's career. 
 
<<r movie_init, eval = F, echo= F, results = 'asis', message = F, warning = F, cache = T>>=

M = as.sociomatrix(movie_net_acw_full, ignore.eval = F, attrname = "ratings_diff")
with(latent_acw2, llik(M, mkl$sender, mkl$receiver, mkl$beta, mkl$Z,
                       mcmc.mle$sender.var, mcmc.mle$receiver.var,
                       mcmc.mle$Z.var,
                       est = est))

N = nrow(M); n = N; D= 2; d = 2; 
v_z = sqrt(N); s2_z = N/8
Z_dist = dist2(Y)
Z = cmdscale(Z_dist, k = D)
Z = Z/max(abs(Z))
sigma2_z = var(as.vector(Z))

a = rnorm(N) #rep(0, N) # #sender
b = rnorm(N) #rep(0, N) # #receiver
sigma2_a = var(a)
sigma2_b = var(b)
B = 0 #intercept

# i checked that this high enough enough maxit
# standard random normal initiation better than latentnet type
# now optim method is implemented in ergmm so any of these
#  methods can be used
theta.bfgs = optim(c(a, b, B, Z, sigma2_a, sigma2_b, 10), fn = llik2,
                   Y = M, d = 2, method = "SANN",
                   lower = c(rep(-Inf, 189), 0, 0, 0),
                   control=list(maxit = 200, fnscale = -1))

@

<<r movie_compare, eval = T, echo = F, results = 'hide', dependson = c("movie_data", "setup"), cache = T, message = FALSE, warning = FALSE, fig.height = 6, fig.cap= "The correlation of latent space model scores and average ratings. The plotting characters are the review counts for each film. Outliers to the linear trend have very few reviews. The green points are those discussed in the paper. " >>=

par(mai = c(.8,.8,.5,.8))
stars1 = scale(movie_net_acw%v%"stars")
vc.acw2 <- scale(vc.acw)

plot(stars1, vc.acw2, use = "complete.obs", type = "n",
     main = "Ratings Compared",  xlim = c(-2.5, 2), ylim = c(-2.5, 2), #one outlier not showen 
     xlab = "Average Star Rating (scaled)", ylab = "2D Latent Space Model Rating (scaled)")
col1 = rep(1, length(stars1)); col1[c(78, 120)] = 3 #highlight deviant
text(labels = movie_net_acw%v%"counts", #paste(movie_net_acw%v%"vertex.names", 
     stars1, vc.acw2, cex = .5, srt = -45, col = col1)
#to see titles in plot:
#text(labels = paste(movie_net_acw%v%"vertex.names", movie_net_acw%v%"counts"),
 #    movie_net_acw%v%"stars", vc.acw, cex = .6, srt = -45)

#add trend line without outliers
x <- which(movie_net_acw%v%"counts"<5)
abline(lm(vc.acw2[-x] ~ stars1[-x]), col = "red")

#check unweighted and weighted correlations
cor(stars1 , vc.acw, use = "complete.obs") #.942
#weighted correlation even higher
boot:::corr(cbind((stars1 )[!is.na(stars1 )], 
           vc.acw[!is.na(stars1 )]),
     w = log((movie_net_acw%v%"counts")[!is.na(stars1)])) #.975

@

It is somewhat surprising to see such a strong correlation between the two ratings methods. This may be due in part to homogeneity in the reviewer pool, which reduces the sources of bias discussed above. MovieLens was organized by a university and all reviewers in our data joined in 2000. The top four occupations of the reviewers are (in decreasing order): college/grad student, other/not specified, executive/managerial and academic/educator. This is certainly not representative of the population at large. The impact of our difference-based network model over average ratings may be more evident when reviewers are more heterogeneous. 

%Because the reviews are strongly correlated - almost all within a third of a point so overall impression the same - and we have no ground truth to compare to
We next consider the additional insight gained through latent space model visualization. An interactive plot of the model output is available on the author's website (\url{http://www.stat.ucla.edu/~jane.carlen/pages/movie_net.html}). Each film is displayed as a node whose position is estimated by the latent space model. The nodes are colored by genre with size scaled to latent space model rating. For comparison, the average ratings are listed next to the movie titles in the drop-down menu and when hovering over a node. For clear visualization, the nodes are limited to displaying their (at most) seven strongest out-edges and nodes that are isolated as a result are not shown. In-degree is not limited in the plot.
%An edge's arrow indicates the direction from lower to higher-rated film. <- removed that for visual clarity

<<r movie_plot, eval = F, echo = F>>=

#not evaluated here. stored as movie_net.html

nodes <- data.frame(id = 1:length(movie_net_acw%v%"vertex.names"), 
                    label = "",
                    #label = movie_net_acw%v%"vertex.names",
                    title = paste(movie_net_acw%v%"vertex.names", round(movie_net_acw%v%"stars",2)), #for selection dropdown
                    value = vc.acw, 
                    group = movie_net_acw%v%"genres") #conveys node size, on a scale from 0-1

edges <- data.frame(from=data.frame(as.edgelist(movie_net_acw))$X1, 
                    to=data.frame(as.edgelist(movie_net_acw))$X2)
                    #value = movie_net_acw%e%"avg_diff")

acw_igraph <- graph.data.frame(edges, directed=TRUE, vertices=nodes)
Z = as.matrix(read.csv("~/Documents/citation/latent_ranking/movie_net_acw_Z.csv")[,2:3])
  
visNetwork(nodes, edges, main = "Movie Network", submain = "latent space positions") %>%
  visIgraphLayout(acw_igraph, layout = "layout.norm",
                  layoutMatrix = Z, type = "full") %>%
  #visOptions(highlightNearest = list(enabled =TRUE, degree = 1)) %>%
  visNodes(#color = list(highlight = list(background = "black")),
           shape = "dot", #shape = "text"
           scaling = list(min = 5, max = 30, label = list(max=20)),
           labelHighlightBold = TRUE,
           borderWidth = .5,
           borderWidthSelected = 2,
           font= list(size = 20, color = "black", strokeWidth = 1)) %>%
  visEdges(shadow = FALSE,
           scaling = list(min = 1, max = 10),
           #selectionWidth = "function(x) {acw_avg_diff}",
           hidden = FALSE,
           #scaling = list(min = 1, max = 10),
           arrows = list(to = list(enabled = FALSE, scaleFactor = 5),
                         middle = list(enabled = TRUE, scaleFactor = 1)),
           color = list(inherit = TRUE, highlight = "red", opacity = 0.04), #, color = "white"
           smooth = list(type = "curvedCW")) %>%
  visOptions(highlightNearest = list(enabled = T, degree = 0.5),
             nodesIdSelection = FALSE, 
             selectedBy = "title") %>%
  visLegend(enabled = TRUE, useGroups=TRUE) %>%
  visInteraction(selectConnectedEdges = TRUE)

@

The movies clearly cluster by genre even though genre was not a term in the model. Even those movies with hybrid genres are placed roughly between their two component genres. However, there are a few films that reside outside of their genre cluster. In those cases the plot can highlight incomplete or incorrect classification. For example, the film \textit{Coogan's Bluff} is categorized as a crime film by MovieLens, but its latent position is among actions and westerns. The Internet Movie Database (\textit{IMDb}) entry for this film describes it as ``An Arizona deputy goes to New York City to escort a fugitive back into custody,'' and the lead role is played by action/crime/western star Clint Eastwood \citep{imdb}. The film clearly has heavy action and western influences which its latent position reveals. If genre labels were missing from the data, we could use the latent positions to fill them in.

The continuous positions from the latent space model are more precise identifiers of a movie's style than a discrete cluster label. This is also true of the journal citation network in Section \ref{Example1}. In both cases the clusters, though discernible in the plots, are irregularly shaped and blend into each other. This makes them difficult to capture through model-based clustering techniques.
%I tried actually apllying two-group and three group cluster models to check this out. 2-group is not good (two central clusters, one with larger variance). 3-group hasn't run successfully yet on the full network and the results on the thinned network weren't very helpful. I may need to use the genres as inital labels, but I'm not sure where the argument is and then we lose the "initial label" benefit. 
Plotting them as we have reveals how they relate to each other, going beyond what strict class labels convey. 

<< pagerank_movie, eval = F, cache = T, echo = F, results = 'hide', dependson = c("setup", "setup_jrss", "pagerank", "movie_data"), fig.keep = 'none', message = F, warning = F>>=

# apply page rank ####

movie.page.rank = page.rank(acw_igraph, damping = .95)$vector

# compare results to other ranks ####

## points in
cor(movie.page.rank, colSums(movie_rating_acw)) #.92

## to cited/citing ratio (cited is points in)
cor(movie.page.rank, colSums(movie_rating_acw)/rowSums(movie_rating_acw)) #.958 - better when normalized
#cor(vc.acw, colSums(movie_rating_acw)/rowSums(movie_rating_acw)) #.44

## number of ratings
cor(movie.page.rank, movie_net_acw%v%"counts") #.68
plot(movie.page.rank, movie_net_acw%v%"counts", pch = "x")

### latent ranking scores
cor(movie.page.rank, vc.acw)
plot(movie.page.rank, vc.acw, type = "n", ylim = c(-4,6))
text(labels = movie_net_acw%v%"vertex.names", movie.page.rank, vc.acw, cex = .5, srt = 90)

# takeaway: most page ranks extremely small (this would be good in search results)

@

\section{Discussion}\label{Discussion}

The latent space network model provides a method for rating objects based on relational data. Unlike standard network-based ranking methods such as PageRank it is not a variant on a centrality measure. Instead, it weighs the relative in and out flow of an object while controlling for its position in space - a position that is in turn determined by its network ties. It is thereby a measure of the object's influence or importance within the network at large. This is advantageous when elements to be rated have some underlying, but difficult to measure, similarities. In our applications these were the statistics journals with one or more sub-type (theoretical, computational, etc.) and films of one or more genre. While the latent space model can therefore be applied to even more dissimilar items, the quasi-Stigler citation model introduced by \citet{varinetal} demands homogeneity. Unfortunately, we are not able to obtain and present citation data for related fields of journals (e.g. economics, applied mathematics) to examine this further in the context of academic journals.
  
Another type of heterogeneity that may bias our results is when some nodes in the network are very poorly connected or even isolated. We saw in the MovieLens example that films with very few reviews are most likely to deviate from an overall ratings correlation. To combat this we could incorporate a film's average star rating as a prior expectation for the receiver coefficient. % [implementable in ergmm or only prior mean 0?] , while keeping the sender coefficients at prior mean zero
We could adjust the strength of the prior by adjusting parameters on the prior variance, potentially scaling to review counts. This would stabilize the results when we subset the network and the co-review counts for some films are very low. Although this is not currently implemented in \pkg{latentnet} it could be incorporated in the future. Among nodes that are fairly well connected, differing levels of connectivity do not seem to compromise model performance, as shown for the MovieLens data.

The latent space model is also valuable for its meaningful visualization of network data, which facilitate user exploration of the network itself. One could use the dynamic plots we present to find journals to submit to or films to watch that are similar to a given one.
%i checked a standard plot and it's OK but not nearly as good:
%plot(movie_net_acw, vertex.col = as.numeric(as.factor(movie_net_acw%v%"genres")), cex = 1.3, edge.col ="grey")
While our journal model performs similarly in terms of rankings to the quasi-Stigler model, the visualization helps us better understand what is driving each journal's rating, and make sense of the differences between the two models. Furthermore, in both applications the visualizations provide nuanced genre detection. Though our models did not include a term to capture genre, the latent space positions naturally clustered in agreement with pre-assigned genres.

It is straightforward to extend the quasi-Newton algorithm to similar latent space models, such as the sociality model in which nodes have a single popularity term rather than seperate incoming and outgoing terms. In addition, 

The speed of the quasi-Newton algorithm enables us to fit larger networks that were practical with MCMC estimation. We are able to fit networks of several hundred nodes in [a few?] minutes. Unfortunatley, the positional estimation portion of the algorithm still slows exponentially, as the size of the data matrix grows. However, because we update the positions simultaneously, we can easily parallelize this, the slowest part of the algorithm. In addition, porting the body of our code to \proglang{C++} using \pkg{Rcpp} will greatly increase speed. These changes should enable us to fit networks of several thousands nodes in several minutes. 

Recently, variational Bayesian inference methods have been developed for latent space network models and implemented in the \pkg{R} package \pkg{VBLPCM}. Using variational Bayesian inference, fitting a two-dimensional latent space sender-receiver model takes a fraction of the time. However, the algorithms developed currently only apply to binary-valued networks, not valued networks of the type discussed here. Given the speed of the quasi-Newton estimation method developed here, and uncertainty in the level of bias introduced by variational techniques we did not undertake to expand the variational methods to valued networks. A further task would be to compare the speed and results of such an expanded variational method to the optimization methods described here.

\break

<<variational_bayes, echo = F, eval = F, results = 'hide'>>=

library(VBLPCM)
v.start<-vblpcmstart(movie_net_acw_full,G=3,model="rsocial",LSTEPS=1e4)
v.start<-vblpcmstart(movie_net_acw_full,model="rsocial",LSTEPS=1e4)
v.fit<-vblpcmfit(v.start,STEPS=50)
plot(v.fit)
plot(gof(v.fit,GOF=~degree))
Z = v.fit$V_z[!isolates_acw_thin,]

@

\begin{appendix}

\section{Appendix: Additional Plots}\label{Appendix1}

<<r latent2_centipede, eval = T, echo = F, cache = T, warning = F, message = F, results = 'hide', dependson= c("setup", "latent_sr2", "setup_jrss", "latent2_stigler"), fig.cap = "Visualizing uncertainty in latent space scores (left) and quasi-Stigler scores (right). The error bars are +/- 1.96 estimates of standard deviation (left) and quasi-variance (right). Comparison of 'comparison intervals' around estimated values, which are equal to 1.96$*$QSE in each direction, and 1.96$*$SE in each direction. Note that due to fit constraints, AMS only has an estimated QSE.">>=

# from plotrix package, but made some changes ####
# added cex arg and commented out something with segs[4, and x axis label

centipede.plot <- function (segs, mct = "mean", lower.limit = "std.error", upper.limit = lower.limit, 
    left.labels = NULL, right.labels = NULL, sort.segs = TRUE, 
    main = "", xlab = NA, pch = 21, vgrid = NA, hgrid = NA, gridcol = "lightgray", 
    mar = NA, col = par("fg"), bg = "green", cex = NULL, ...) 
{
    if (missing(segs)) {
        cat("Usage: centipede.plot(segs,...)\n\twhere segs is a dstat object")
        stop("or a matrix of midpoints and limits")
    }
    if (is.list(segs)) {
        if (all(lapply(segs, is.numeric))) 
            segs <- get.segs(segs, mct = mct, lower.limit = lower.limit, 
                upper.limit = upper.limit)
        else stop("If segs is a list, all the components must be numeric")
    }
    if (class(segs) == "dstat") {
        midpoint <- "mean"
        if (lower.limit == "var") {
            if (rownames(segs)[2] == "var") 
                ll <- segs[1, ] - segs[2, ]
            if (rownames(segs)[2] == "sd") 
                ll <- segs[1, ] - segs[2, ] * segs[2, ]
        }
        if (upper.limit == "var") {
            if (rownames(segs)[2] == "var") 
                ul <- segs[1, ] + segs[2, ]
            if (rownames(segs)[2] == "sd") 
                ul <- segs[1, ] + segs[2, ] * segs[2, ]
        }
        if (lower.limit == "sd") {
            if (rownames(segs)[2] == "var") 
                ll <- segs[1, ] - sqrt(segs[2, ])
            if (rownames(segs)[2] == "sd") 
                ll <- segs[1, ] - segs[2, ]
        }
        if (upper.limit == "sd") {
            if (rownames(segs)[2] == "var") 
                ul <- segs[1, ] + sqrt(segs[2, ])
            if (rownames(segs)[2] == "sd") 
                ul <- segs[1, ] + segs[2, ]
        }
        if (lower.limit == "std.error") {
            if (rownames(segs)[2] == "var") 
                ll <- segs[1, ] - sqrt(segs[2, ])/sqrt(segs[3, 
                  ])
            if (rownames(segs)[2] == "sd") 
                ll <- segs[1, ] - segs[2, ]/sqrt(segs[3, ])
        }
        if (upper.limit == "std.error") {
            if (rownames(segs)[2] == "var") 
                ul <- segs[1, ] + sqrt(segs[2, ])/sqrt(segs[3, 
                  ])
            if (rownames(segs)[2] == "sd") 
                ul <- segs[1, ] + segs[2, ]/sqrt(segs[3, ])
        }
        segs <- rbind(segs[1, ], ll, ul, segs[3, ])
    }
    segdim <- dim(segs)
    if (sort.segs) {
        seg.order <- order(segs[1, ])
        segs <- segs[, seg.order]
    }
    else seg.order <- 1:segdim[2]
    oldpar <- par("mar")
    #if (is.na(mar[1])) 
    #    mar <- c(4, 6, 1 + 2 * (nchar(main) > 0), 5)
    #par(mar = mar)
    plot(x = c(min(segs[2, ]), max(segs[3, ])), y = c(1, segdim[2]), 
        main = main, xlab = "", ylab = "", type = "n", axes = FALSE, 
        ...)
    box()
    if (!is.na(vgrid[1])) 
        abline(v = vgrid, lty = 1, col = gridcol)
    if (is.null(hgrid)) 
        abline(h = 1:segdim[2], lty = 2, col = gridcol)
    else if (!is.na(hgrid[1])) 
        abline(h = hgrid, lty = 2, col = gridcol)
    axis(1, cex.axis = cex)
    arrows(segs[2, ], 1:segdim[2], segs[3, ], 1:segdim[2], length = 0.05, 
        angle = 90, code = 3, col = col)
    points(segs[1, ], 1:segdim[2], pch = pch, col = col, bg = bg)
    if (is.null(left.labels)) {
        left.labels <- colnames(segs)
        if (is.null(left.labels)) 
            left.labels <- paste("V", seg.order, sep = "")
    }
    else left.labels <- left.labels[seg.order]
    plot.limits <- par("usr")
    mtext(left.labels, 2, line = 0.2, at = 1:segdim[2], adj = 1, 
        las = 1, cex = cex)
    #if (is.null(right.labels)) 
    #    right.labels <- paste(round(segs[1, ], 2), "(", segs[4, 
    #        ], ")", sep = "")
    #else 
    right.labels <- right.labels[seg.order]
    mtext(right.labels, 4, line = 0.2, at = 1:segdim[2], adj = 0, 
        las = 1, cex = cex)
    #if (is.na(xlab)) 
    #    xlab <- paste("| -", rownames(segs)[2], "-", rownames(segs)[1], 
    #        "-", rownames(segs)[3], "- |")
    if (!is.na(xlab)) 
        mtext(xlab, 1, line = 2)
    par(oldpar)
    invisible(segs)
}

# 2-D latent space variance by sample ####
model = latent.srp2.init.r
sd2 = apply(model$sample$receiver - model$sample$sender, 2, sd)
latent2 = model$mkl$receiver - model$mkl$sender
centipede1 = t(cbind(latent2, latent2 - 1.96*sd2, latent2 + 1.96*sd2))
colnames(centipede1) = Cnet%v%"vertex.names"

# QSE using glm output (account for overdispersion) ####
shift = mean(g1$coefficients)
v = c(0, diag(vcov(g1))) #vcov(g1) = summary(g1)$cov.scaled = summary(g1)$cov.unscaled*phi 
centipede.qse = (cbind(fit.table2$quasi,
                        fit.table2$quasi - 1.96*fit.table2$qse,
                        fit.table2$quasi + 1.96*fit.table2$qse)) 

centipede.se = (cbind(g1$coefficients - shift,
                       g1$coefficients - shift - 1.96*sqrt(v), 
                       g1$coefficients - shift + 1.96*sqrt(v)))
rownames(centipede.se) = rownames(fit.table2)

#plot ####
par(mfrow = c(1,2))
centipede.plot(centipede1, vgrid = c(-1,0,1,2), cex = .7, right.labels = round(latent2, 2),
               bg = "red", main = "2-D Latent Space")

centipede.plot(t(centipede.se), vgrid = c(-1,0,1,2), cex = .7, 
               right.labels = round(fit.table2$quasi, 2), 
               left.labels = rownames(fit.table2), 
               bg = c("blue"), col = c("blue"),
               main = "Quasi-Stigler SE and QSE Intervals",
               xlim = c(-2, 2.5))
par(new=TRUE)
centipede.plot(t(centipede.qse), cex = .7,
               bg = c("blue"), col = c("cyan"),
               left.labels = " ",
               right.labels = " ",
               xlim = c(-2, 2.5))
legend("bottomright", legend = c("SE", "QSE"), col = c("blue", "cyan"), pch = 15)

# summary of ses
summary(sqrt(v)[v>0])
summary(sd2)
@

\noindent \section{Appendix: Derivatives for Quasi-Newton Algorithm}\label{Appendix2}


\textbf{1. The posterior log likelihood function of interest, up to a constant (denoted $\mathbbm{llik}$):}
\begin{multline*}
$$ \displaystyle log(P(\theta|Y)) = \sum_{i}\sum_{j \neq i} y_{ij}(\beta + a_i + b_j - \lVert z_i - z_j \rVert) + exp(\beta + a_i + b_j - \lVert z_i - z_j \rVert) - log(y_ij!)~+ \\
  \sum_i log(\frac{1}{\sqrt{2\pi\sigma^2_a}}exp(\frac{-a^2_i}{2\sigma^2_a})) ~+~
  \sum_i log(\frac{1}{\sqrt{2\pi\sigma^2_b}}exp(\frac{-b^2_i}{2\sigma^2_b})) ~+~
  \sum_{i,d} log(\frac{1}{\sqrt{2\pi\sigma^2_z}}exp(\frac{-z^2_{i,d}}{2\sigma^2_z})) ~+~ 
  log(\frac{1}{\sqrt{2\pi\sigma^2_\beta}}exp(\frac{-\beta^2}{2\sigma^2_\beta}))~ + ~\\
  log(\frac{s^2_a\frac{v_a}{2}}{\Gamma(\frac{v_a}{2})})
    ~-~  \frac{v_as^2_a}{2\sigma^2_a} ~-~ log(\sigma^2_a)(1+\frac{v_a}{2}) ~+~
  log(\frac{s^2_b\frac{v_b}{2}}{\Gamma(\frac{v_b}{2})}) 
    ~-~  \frac{v_bs^2_b}{2\sigma^2_b} ~-~ log(\sigma^2_b)(1+\frac{v_b}{2}) ~+~
  log(\frac{s^2_z\frac{v_z}{2}}{\Gamma(\frac{v_z}{2})}) 
    ~-~  \frac{v_zs^2_z}{2\sigma^2_z} ~-~ log(\sigma^2_z)(1+\frac{v_z}{2}) \\
  $$
\end{multline*}

\noindent \textbf{2. First-order Partial Derivatives:} \newline

\noindent Calculations assume no self-edges, $y_{ii} = 0, \forall~1 \leq i \leq n$.

$$\displaystyle  \frac{\partial \mathbbm{llik}}{\partial a_i} = - \frac{a_i}{\sigma^2_a} + \sum_{j \neq i} y_{ij} - exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert)$$

$$\displaystyle  \frac{\partial \mathbbm{llik}}{\partial b_i} = - \frac{b_i}{\sigma^2_b} + \sum_{j \neq i} y_{ji} - exp(\beta +a_j + b_i - \lVert z_i - z_j \rVert)$$

$$\displaystyle \frac{\partial \mathbbm{llik}}{\partial \beta} = - \frac{\beta}{\sigma^2_\beta} + \sum_i \sum_{j \neq i} y_{ij} - exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert))$$

\begin{align*}
\displaystyle \frac{\partial \mathbbm{llik}}{\partial z_{i,d}} &= - \frac{z_{i,d}}{\sigma^2_z} + \sum_{j \neq i} \frac{\partial \mathbbm{llik}}{\partial z_{i,d}}(\lVert z_i - z_j \rVert) \Big[ -y_{ij} - y_{ji} + exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert) + exp(\beta +a_j + b_i - \lVert z_i - z_j \rVert) \Big] \\
  &= - \frac{z_{i,d}}{\sigma^2_z} +
  \sum_{j \neq i} \frac{1}{\lVert z_i - z_j \rVert}(z_{i,d}-z_{j,d}) \Big[ -y_{ij} - y_{ji} + exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert) + exp(\beta +a_j + b_i - \lVert z_i - z_j \rVert) \Big]
\end{align*}

\noindent For variance parameters we can solve the first order partial for 0. We outline the calculation for $\sigma^2_a$. 

$$\displaystyle \frac{\partial \mathbbm{llik}}{
\partial \sigma^2_a} = n(2\pi\sigma^2_a)^{-1}\pi + \sum_i\frac{a_i^2}{2}(\sigma^2_a)^{-2} + \frac{v_as_a^2(\sigma^2_a)^{-2}}{2} - (1+\frac{v_a}{2})(\sigma^2_a)^{-1} = 0$$

$$\displaystyle (\sigma^2_a)^{-1}(\sum_i\frac{a_i^2}{2} + \frac{v_as_a^2}{2}) = \frac{n}{2} + (1+\frac{v_a}{2})$$


$$\displaystyle \sigma^2_a = \frac{v_a s^2_a + \sum_i a_i^2}{n + 2 + v_a}$$
$$\displaystyle \sigma^2_b = \frac{v_b s^2_b + \sum_i b_i^2}{n + 2 + v_b}$$
$$\displaystyle \sigma^2_z = \frac{v_z s^2_z + \sum_{i,d} z_{i,d}^2}{n*D + 2 + v_z}$$

\break

\noindent \textbf{ 3. Second-order Partial Derivatives: } \newline

$$\displaystyle \frac{\partial^2 \mathbbm{llik}}{\partial a^2_i} = \sum_{j \neq i} - exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert) - \frac{1}{\sigma^2_a} < 0$$

$$\displaystyle \frac{\partial^2 \mathbbm{llik}}{\partial b^2_i} = \sum_{j \neq i} - exp(\beta +a_j + b_i - \lVert z_i - z_j \rVert) - \frac{1}{\sigma^2_b} < 0$$

$$\displaystyle \frac{\partial^2 \mathbbm{llik}}{\partial \beta^2} = - \frac{1}{\sigma^2_\beta} + \sum_i \sum_{j \neq i} - exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert)) < 0$$

$$\displaystyle \frac{\partial \mathbbm{llik}}{
\partial^2 \sigma^2_a} = -(\sigma^2_a)^{-2}(\sum_i\frac{a_i^2}{2} + \frac{v_as_a^2}{2}) < 0$$ \\

\noindent let $exp(IJ) = exp(\beta +a_i + b_j - \lVert z_i - z_j \rVert)$ \\
let $exp(JI) = exp(\beta +a_j + b_i - \lVert z_i - z_j \rVert)$

\begin{align*}
\displaystyle \frac{\partial^2 \mathbbm{llik}}{\partial z^2_{i,d}} & = - \frac{1}{\sigma^2_z} + \sum_{j \neq i} \Big[-\frac{1}{\lVert z_i - z_j \rVert^3}(z_{i,d}-z_{j,d})^2 + \frac{1}{\lVert z_i - z_j \rVert} \Big] \Big[ -y_{ij} - y_{ji} + exp(IJ) + exp(JI) \Big] - \\
& \indent \sum_{j \neq i} \Big[\frac{1}{\lVert z_i - z_j \rVert^2}(z_{i,d}-z_{j,d})^2\Big](exp(IJ) + exp(JI)) \\
& = - \frac{1}{\sigma^2_z} + \sum_{j \neq i} \frac{1}{\lVert z_i - z_j \rVert^3}(z_{i,d}-z_{j,d})^2
\Big[ y_{ij} + y_{ji} - (exp(IJ) + exp(JI))(1 + \lVert z_i - z_j \rVert) \Big] + \\
& \indent \sum_{j \neq i}\frac{1}{\lVert z_i - z_j \rVert}\Big[ - y_{ij} - y_{ji} + exp(IJ) + exp(JI) \Big]
\Big]
\end{align*}

\end{appendix}

\newpage

\bibliographystyle{apacite}
\bibliography{latent_ranking}

\end{document}